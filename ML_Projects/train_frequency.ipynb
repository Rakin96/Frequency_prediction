{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Datset and Converting to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/rakin/ML_Projects/new.csv\")\n",
    "df = df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.values[:,-3:] # Target\n",
    "X = df.values[:,:-3] # Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the target variables using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "target1 = scaler2.fit_transform(Y_train[:,0].reshape(-1,1))  # \n",
    "target2 = scaler.fit_transform(Y_train[:,1].reshape(-1,1))\n",
    "target3 = scaler.fit_transform(Y_train[:,2].reshape(-1,1))\n",
    "\n",
    "# Concatenate the normalized target variables\n",
    "\n",
    "Y_train = np.concatenate((target1, target2, target3), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "# filepath='./val_aux_output_accuracy:{val_accuracy:.3f}-epochs:{epoch:03d}.hdf5'\n",
    "filepath = './Best_model_6.hdf5'\n",
    "#earlyStopping = EarlyStopping(monitor='val_aux_output_loss', patience=10, verbose=0, mode='min')\n",
    "#mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mse', verbose = 1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.5, mode='min',patience=2,verbose=1,min_lr=0.0001)\n",
    "#callbacks_list = [checkpoint]\n",
    "callbacks_list = [checkpoint,reduce_lr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify This cell - Try USing XGBoosRegressor, RandomForestRegressor, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.1591 - mse: 0.1591\n",
      "Epoch 1: val_mse improved from inf to 3989.38721, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 3s 44ms/step - loss: 0.1568 - mse: 0.1568 - val_loss: 3989.3872 - val_mse: 3989.3872 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 2: val_mse improved from 3989.38721 to 1164.96594, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 1164.9659 - val_mse: 1164.9659 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 3: val_mse improved from 1164.96594 to 639.93347, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 639.9335 - val_mse: 639.9335 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 4: val_mse improved from 639.93347 to 247.77907, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 247.7791 - val_mse: 247.7791 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/16 [=================>............] - ETA: 0s - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 5: val_mse improved from 247.77907 to 84.58349, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 84.5835 - val_mse: 84.5835 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 6: val_mse improved from 84.58349 to 73.53657, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 73.5366 - val_mse: 73.5366 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 7: val_mse improved from 73.53657 to 24.22881, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 24.2288 - val_mse: 24.2288 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 8: val_mse improved from 24.22881 to 11.76166, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 11.7617 - val_mse: 11.7617 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 9: val_mse improved from 11.76166 to 3.66855, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 3.6686 - val_mse: 3.6686 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 10: val_mse improved from 3.66855 to 1.40719, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 1.4072 - val_mse: 1.4072 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 11: val_mse improved from 1.40719 to 1.18038, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 1.1804 - val_mse: 1.1804 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 12: val_mse did not improve from 1.18038\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 2.3042 - val_mse: 2.3042 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 13: val_mse improved from 1.18038 to 0.37109, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.3711 - val_mse: 0.3711 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 14: val_mse improved from 0.37109 to 0.24563, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.2456 - val_mse: 0.2456 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 15: val_mse did not improve from 0.24563\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.3043 - val_mse: 0.3043 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 16: val_mse did not improve from 0.24563\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.2658 - val_mse: 0.2658 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 17: val_mse improved from 0.24563 to 0.12217, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.1222 - val_mse: 0.1222 - lr: 5.0000e-04\n",
      "Epoch 18/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 18: val_mse improved from 0.12217 to 0.10835, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.1084 - val_mse: 0.1084 - lr: 5.0000e-04\n",
      "Epoch 19/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 19: val_mse improved from 0.10835 to 0.03585, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0358 - val_mse: 0.0358 - lr: 5.0000e-04\n",
      "Epoch 20/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 20: val_mse improved from 0.03585 to 0.02234, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0223 - val_mse: 0.0223 - lr: 5.0000e-04\n",
      "Epoch 21/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 21: val_mse improved from 0.02234 to 0.01922, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0192 - val_mse: 0.0192 - lr: 5.0000e-04\n",
      "Epoch 22/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 22: val_mse did not improve from 0.01922\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0289 - val_mse: 0.0289 - lr: 5.0000e-04\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 23: val_mse improved from 0.01922 to 0.01046, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0105 - val_mse: 0.0105 - lr: 5.0000e-04\n",
      "Epoch 24/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 24: val_mse did not improve from 0.01046\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0111 - val_mse: 0.0111 - lr: 5.0000e-04\n",
      "Epoch 25/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 25: val_mse improved from 0.01046 to 0.00666, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0067 - val_mse: 0.0067 - lr: 5.0000e-04\n",
      "Epoch 26/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 26: val_mse did not improve from 0.00666\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0114 - val_mse: 0.0114 - lr: 5.0000e-04\n",
      "Epoch 27/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 27: val_mse improved from 0.00666 to 0.00487, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0049 - val_mse: 0.0049 - lr: 5.0000e-04\n",
      "Epoch 28/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 28: val_mse did not improve from 0.00487\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0056 - lr: 5.0000e-04\n",
      "Epoch 29/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 29: val_mse improved from 0.00487 to 0.00326, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0033 - val_mse: 0.0033 - lr: 5.0000e-04\n",
      "Epoch 30/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020 - mse: 0.0020       \n",
      "Epoch 30: val_mse did not improve from 0.00326\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0058 - val_mse: 0.0058 - lr: 5.0000e-04\n",
      "Epoch 31/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 31: val_mse improved from 0.00326 to 0.00289, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0029 - val_mse: 0.0029 - lr: 5.0000e-04\n",
      "Epoch 32/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 32: val_mse did not improve from 0.00289\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0046 - val_mse: 0.0046 - lr: 5.0000e-04\n",
      "Epoch 33/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 33: val_mse improved from 0.00289 to 0.00193, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0019 - val_mse: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 34/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 34: val_mse did not improve from 0.00193\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0024 - val_mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 35/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 35: val_mse did not improve from 0.00193\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0028 - val_mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 36/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 36: val_mse did not improve from 0.00193\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0029 - val_mse: 0.0029 - lr: 2.5000e-04\n",
      "Epoch 37/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 37: val_mse improved from 0.00193 to 0.00136, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 38/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 38: val_mse did not improve from 0.00136\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 2.5000e-04\n",
      "Epoch 39/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 39: val_mse did not improve from 0.00136\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0016 - val_mse: 0.0016 - lr: 2.5000e-04\n",
      "Epoch 40/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0014       \n",
      "Epoch 40: val_mse improved from 0.00136 to 0.00130, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.2500e-04\n",
      "Epoch 41/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 41: val_mse did not improve from 0.00130\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0016 - val_mse: 0.0016 - lr: 1.2500e-04\n",
      "Epoch 42/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 42: val_mse improved from 0.00130 to 0.00128, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 43: val_mse did not improve from 0.00128\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0019 - val_mse: 0.0019 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 44: val_mse improved from 0.00128 to 0.00120, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 45: val_mse improved from 0.00120 to 0.00120, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 46: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 47: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 48: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0015      \n",
      "Epoch 49: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 50: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 51: val_mse did not improve from 0.00120\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 52: val_mse improved from 0.00120 to 0.00119, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 53: val_mse did not improve from 0.00119\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0015 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 54: val_mse did not improve from 0.00119\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0015       \n",
      "Epoch 55: val_mse did not improve from 0.00119\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 56: val_mse did not improve from 0.00119\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 1.0000e-04\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012      \n",
      "Epoch 57: val_mse did not improve from 0.00119\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 58/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0012       \n",
      "Epoch 58: val_mse improved from 0.00119 to 0.00118, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 59/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 59: val_mse did not improve from 0.00118\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 1.0000e-04\n",
      "Epoch 60/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 60: val_mse did not improve from 0.00118\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 1.0000e-04\n",
      "Epoch 61/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 61: val_mse did not improve from 0.00118\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 62/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 62: val_mse did not improve from 0.00118\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 63/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 63: val_mse did not improve from 0.00118\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 64/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 64: val_mse improved from 0.00118 to 0.00117, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 65/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0014       \n",
      "Epoch 65: val_mse improved from 0.00117 to 0.00112, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 66/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0012      \n",
      "Epoch 66: val_mse did not improve from 0.00112\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 67/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 67: val_mse did not improve from 0.00112\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 68/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 68: val_mse did not improve from 0.00112\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 69/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0015      \n",
      "Epoch 69: val_mse did not improve from 0.00112\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 70/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 70: val_mse improved from 0.00112 to 0.00112, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 71/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 71: val_mse did not improve from 0.00112\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 72/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 72: val_mse improved from 0.00112 to 0.00110, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 73/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 73: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0015 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 74/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 74: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 75/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 75: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 76/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 76: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 77/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 77: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 78/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 78: val_mse improved from 0.00110 to 0.00110, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 79/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 79: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 80: val_mse improved from 0.00110 to 0.00110, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 81/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 81: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 82/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 82: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 83/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 83: val_mse did not improve from 0.00110\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 84/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 84: val_mse improved from 0.00110 to 0.00107, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 85/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 85: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 86/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 86: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 87/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0012 - mse: 0.0012       \n",
      "Epoch 87: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 88/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 88: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 89/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0013     \n",
      "Epoch 89: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 90/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 90: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 91/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 91: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 92/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 92: val_mse did not improve from 0.00107\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 93/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0013      \n",
      "Epoch 93: val_mse improved from 0.00107 to 0.00106, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 94/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 94: val_mse improved from 0.00106 to 0.00106, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 95: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 96: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 97/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 97: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 98/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 98: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 99/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0015       \n",
      "Epoch 99: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 100/300\n",
      "10/16 [=================>............] - ETA: 0s - loss: 8.6364e-04 - mse: 8.6364e-04\n",
      "Epoch 100: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 101/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 101: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 102: val_mse did not improve from 0.00106\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 103: val_mse improved from 0.00106 to 0.00104, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 104/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 104: val_mse did not improve from 0.00104\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 105/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 105: val_mse did not improve from 0.00104\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 106/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014 - mse: 0.0014       \n",
      "Epoch 106: val_mse did not improve from 0.00104\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0015 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 107/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 107: val_mse did not improve from 0.00104\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 108/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 108: val_mse improved from 0.00104 to 0.00104, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 109/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011      \n",
      "Epoch 109: val_mse improved from 0.00104 to 0.00103, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 110/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0012     \n",
      "Epoch 110: val_mse did not improve from 0.00103\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 111/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 111: val_mse did not improve from 0.00103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 112/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 112: val_mse did not improve from 0.00103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 113/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 9.8842e-04 - mse: 9.8842e-04\n",
      "Epoch 113: val_mse did not improve from 0.00103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 114/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013       \n",
      "Epoch 114: val_mse did not improve from 0.00103\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 115/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 115: val_mse improved from 0.00103 to 0.00102, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 116/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.5403e-04 - mse: 9.5403e-04\n",
      "Epoch 116: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011      \n",
      "Epoch 117: val_mse improved from 0.00102 to 0.00102, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011      \n",
      "Epoch 118: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 119/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 119: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.8114e-04 - mse: 9.8114e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 120/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 120: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 121/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 121: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 122/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 122: val_mse did not improve from 0.00102\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 123/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011      \n",
      "Epoch 123: val_mse improved from 0.00102 to 0.00101, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 124/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 124: val_mse did not improve from 0.00101\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 125/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 125: val_mse did not improve from 0.00101\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 126/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 126: val_mse did not improve from 0.00101\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 127/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.0016e-04 - mse: 9.0016e-04\n",
      "Epoch 127: val_mse did not improve from 0.00101\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0016 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 128/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0010      \n",
      "Epoch 128: val_mse did not improve from 0.00101\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0014 - val_mse: 0.0014 - lr: 1.0000e-04\n",
      "Epoch 129/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 129: val_mse improved from 0.00101 to 0.00098, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.7670e-04 - val_mse: 9.7670e-04 - lr: 1.0000e-04\n",
      "Epoch 130/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 130: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 131/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0013      \n",
      "Epoch 131: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 132/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.8543e-04 - mse: 9.8543e-04\n",
      "Epoch 132: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 9.7267e-04 - mse: 9.7267e-04 - val_loss: 9.9185e-04 - val_mse: 9.9185e-04 - lr: 1.0000e-04\n",
      "Epoch 133/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 8.9695e-04 - mse: 8.9695e-04\n",
      "Epoch 133: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.3926e-04 - mse: 9.3926e-04 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 134: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 135: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.8947e-04 - val_mse: 9.8947e-04 - lr: 1.0000e-04\n",
      "Epoch 136/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 136: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 9.8897e-04 - mse: 9.8897e-04 - val_loss: 9.9496e-04 - val_mse: 9.9496e-04 - lr: 1.0000e-04\n",
      "Epoch 137/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 137: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 138/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 138: val_mse did not improve from 0.00098\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 139/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 139: val_mse improved from 0.00098 to 0.00097, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.6571e-04 - val_mse: 9.6571e-04 - lr: 1.0000e-04\n",
      "Epoch 140/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.0865e-04 - mse: 9.0865e-04\n",
      "Epoch 140: val_mse improved from 0.00097 to 0.00096, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 9.0670e-04 - mse: 9.0670e-04 - val_loss: 9.5804e-04 - val_mse: 9.5804e-04 - lr: 1.0000e-04\n",
      "Epoch 141/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 141: val_mse did not improve from 0.00096\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.7083e-04 - val_mse: 9.7083e-04 - lr: 1.0000e-04\n",
      "Epoch 142/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 142: val_mse did not improve from 0.00096\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.6393e-04 - val_mse: 9.6393e-04 - lr: 1.0000e-04\n",
      "Epoch 143/300\n",
      " 8/16 [==============>...............] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 143: val_mse improved from 0.00096 to 0.00095, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 9.4958e-04 - val_mse: 9.4958e-04 - lr: 1.0000e-04\n",
      "Epoch 144/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.4993e-04 - mse: 8.4993e-04\n",
      "Epoch 144: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 8.9588e-04 - mse: 8.9588e-04 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 145/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 145: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 146: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 147/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.4255e-04 - mse: 9.4255e-04\n",
      "Epoch 147: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 9.6859e-04 - mse: 9.6859e-04 - val_loss: 9.6968e-04 - val_mse: 9.6968e-04 - lr: 1.0000e-04\n",
      "Epoch 148/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0012       \n",
      "Epoch 148: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 9.8651e-04 - val_mse: 9.8651e-04 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 149: val_mse improved from 0.00095 to 0.00095, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.4810e-04 - val_mse: 9.4810e-04 - lr: 1.0000e-04\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 150: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011  \n",
      "Epoch 151: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.8692e-04 - val_mse: 9.8692e-04 - lr: 1.0000e-04\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 152: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 153/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.3196e-04 - mse: 9.3196e-04\n",
      "Epoch 153: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.2567e-04 - mse: 9.2567e-04 - val_loss: 9.6676e-04 - val_mse: 9.6676e-04 - lr: 1.0000e-04\n",
      "Epoch 154/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.9626e-04 - mse: 8.9626e-04\n",
      "Epoch 154: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 9.1722e-04 - mse: 9.1722e-04 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.3237e-04 - mse: 9.3237e-04\n",
      "Epoch 155: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.7795e-04 - mse: 9.7795e-04\n",
      "Epoch 156: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 9.8598e-04 - mse: 9.8598e-04 - val_loss: 9.5123e-04 - val_mse: 9.5123e-04 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 157: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.4679e-04 - mse: 9.4679e-04\n",
      "Epoch 158: val_mse did not improve from 0.00095\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.4841e-04 - mse: 9.4841e-04\n",
      "Epoch 159: val_mse improved from 0.00095 to 0.00094, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 9.4841e-04 - mse: 9.4841e-04 - val_loss: 9.4119e-04 - val_mse: 9.4119e-04 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2187e-04 - mse: 9.2187e-04\n",
      "Epoch 160: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 9.3075e-04 - mse: 9.3075e-04 - val_loss: 9.6282e-04 - val_mse: 9.6282e-04 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.8076e-04 - mse: 9.8076e-04\n",
      "Epoch 161: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012      \n",
      "Epoch 162: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 163: val_mse improved from 0.00094 to 0.00094, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 9.9418e-04 - mse: 9.9418e-04 - val_loss: 9.3789e-04 - val_mse: 9.3789e-04 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8397e-04 - mse: 9.8397e-04\n",
      "Epoch 164: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.9685e-04 - val_mse: 9.9685e-04 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 165: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.5229e-04 - val_mse: 9.5229e-04 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011        \n",
      "Epoch 166: val_mse did not improve from 0.00094\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 167: val_mse improved from 0.00094 to 0.00093, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.3422e-04 - val_mse: 9.3422e-04 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 8.7722e-04 - mse: 8.7722e-04\n",
      "Epoch 168: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.3941e-04 - val_mse: 9.3941e-04 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0710e-04 - mse: 9.0710e-04\n",
      "Epoch 169: val_mse improved from 0.00093 to 0.00093, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.0710e-04 - mse: 9.0710e-04 - val_loss: 9.2551e-04 - val_mse: 9.2551e-04 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0224e-04 - mse: 9.0224e-04\n",
      "Epoch 170: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 9.0224e-04 - mse: 9.0224e-04 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.8710e-04 - mse: 9.8710e-04\n",
      "Epoch 171: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 9.8710e-04 - mse: 9.8710e-04 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 172/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.7810e-04 - mse: 9.7810e-04\n",
      "Epoch 172: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0016 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 173/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 173: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 174/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.3185e-04 - mse: 9.3185e-04\n",
      "Epoch 174: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 9.3161e-04 - mse: 9.3161e-04 - val_loss: 9.3221e-04 - val_mse: 9.3221e-04 - lr: 1.0000e-04\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.7613e-04 - mse: 8.7613e-04\n",
      "Epoch 175: val_mse did not improve from 0.00093\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 8.7613e-04 - mse: 8.7613e-04 - val_loss: 9.6008e-04 - val_mse: 9.6008e-04 - lr: 1.0000e-04\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.4637e-04 - mse: 8.4637e-04\n",
      "Epoch 176: val_mse improved from 0.00093 to 0.00091, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 8.4637e-04 - mse: 8.4637e-04 - val_loss: 9.1062e-04 - val_mse: 9.1062e-04 - lr: 1.0000e-04\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 177: val_mse did not improve from 0.00091\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 9.4891e-04 - val_mse: 9.4891e-04 - lr: 1.0000e-04\n",
      "Epoch 178/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.8648e-04 - mse: 9.8648e-04\n",
      "Epoch 178: val_mse did not improve from 0.00091\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.5975e-04 - val_mse: 9.5975e-04 - lr: 1.0000e-04\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014      \n",
      "Epoch 179: val_mse improved from 0.00091 to 0.00091, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 9.0637e-04 - val_mse: 9.0637e-04 - lr: 1.0000e-04\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.9696e-04 - mse: 9.9696e-04\n",
      "Epoch 180: val_mse improved from 0.00091 to 0.00090, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.9696e-04 - mse: 9.9696e-04 - val_loss: 9.0427e-04 - val_mse: 9.0427e-04 - lr: 1.0000e-04\n",
      "Epoch 181/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2996e-04 - mse: 9.2996e-04\n",
      "Epoch 181: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 9.3456e-04 - mse: 9.3456e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 182/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8953e-04 - mse: 9.8953e-04\n",
      "Epoch 182: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.1816e-04 - val_mse: 9.1816e-04 - lr: 1.0000e-04\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012       \n",
      "Epoch 183: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010    \n",
      "Epoch 184: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.4285e-04 - val_mse: 9.4285e-04 - lr: 1.0000e-04\n",
      "Epoch 185/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 185: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.6000e-04 - val_mse: 9.6000e-04 - lr: 1.0000e-04\n",
      "Epoch 186/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 186: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.1772e-04 - val_mse: 9.1772e-04 - lr: 1.0000e-04\n",
      "Epoch 187/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6199e-04 - mse: 9.6199e-04\n",
      "Epoch 187: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 9.1365e-04 - mse: 9.1365e-04 - val_loss: 9.1105e-04 - val_mse: 9.1105e-04 - lr: 1.0000e-04\n",
      "Epoch 188/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.7664e-04 - mse: 9.7664e-04\n",
      "Epoch 188: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 9.7615e-04 - mse: 9.7615e-04 - val_loss: 9.0815e-04 - val_mse: 9.0815e-04 - lr: 1.0000e-04\n",
      "Epoch 189/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.2136e-04 - mse: 9.2136e-04\n",
      "Epoch 189: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.1818e-04 - mse: 9.1818e-04 - val_loss: 9.2121e-04 - val_mse: 9.2121e-04 - lr: 1.0000e-04\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.7850e-04 - mse: 9.7850e-04\n",
      "Epoch 190: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 9.7850e-04 - mse: 9.7850e-04 - val_loss: 9.2910e-04 - val_mse: 9.2910e-04 - lr: 1.0000e-04\n",
      "Epoch 191/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 7.2027e-04 - mse: 7.2027e-04\n",
      "Epoch 191: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.5529e-04 - mse: 7.5529e-04 - val_loss: 9.3302e-04 - val_mse: 9.3302e-04 - lr: 1.0000e-04\n",
      "Epoch 192/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.2654e-04 - mse: 9.2654e-04\n",
      "Epoch 192: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 193/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.8216e-04 - mse: 9.8216e-04\n",
      "Epoch 193: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.6538e-04 - mse: 9.6538e-04\n",
      "Epoch 194: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 9.6538e-04 - mse: 9.6538e-04 - val_loss: 9.0695e-04 - val_mse: 9.0695e-04 - lr: 1.0000e-04\n",
      "Epoch 195/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 195: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 196/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.8602e-04 - mse: 9.8602e-04\n",
      "Epoch 196: val_mse did not improve from 0.00090\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 197/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.8826e-04 - mse: 8.8826e-04\n",
      "Epoch 197: val_mse improved from 0.00090 to 0.00089, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.9342e-04 - mse: 8.9342e-04 - val_loss: 8.9423e-04 - val_mse: 8.9423e-04 - lr: 1.0000e-04\n",
      "Epoch 198/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 198: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.4489e-04 - val_mse: 9.4489e-04 - lr: 1.0000e-04\n",
      "Epoch 199/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 199: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.0534e-04 - val_mse: 9.0534e-04 - lr: 1.0000e-04\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.7813e-04 - mse: 8.7813e-04\n",
      "Epoch 200: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 8.7813e-04 - mse: 8.7813e-04 - val_loss: 9.3072e-04 - val_mse: 9.3072e-04 - lr: 1.0000e-04\n",
      "Epoch 201/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7060e-04 - mse: 8.7060e-04\n",
      "Epoch 201: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 8.9571e-04 - mse: 8.9571e-04 - val_loss: 9.8590e-04 - val_mse: 9.8590e-04 - lr: 1.0000e-04\n",
      "Epoch 202/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 8.7968e-04 - mse: 8.7968e-04\n",
      "Epoch 202: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 8.8465e-04 - mse: 8.8465e-04 - val_loss: 9.7350e-04 - val_mse: 9.7350e-04 - lr: 1.0000e-04\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.8970e-04 - mse: 9.8970e-04\n",
      "Epoch 203: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 9.8970e-04 - mse: 9.8970e-04 - val_loss: 9.6004e-04 - val_mse: 9.6004e-04 - lr: 1.0000e-04\n",
      "Epoch 204/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.6825e-04 - mse: 8.6825e-04\n",
      "Epoch 204: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 8.9972e-04 - mse: 8.9972e-04 - val_loss: 9.2132e-04 - val_mse: 9.2132e-04 - lr: 1.0000e-04\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 205: val_mse improved from 0.00089 to 0.00089, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 8.9367e-04 - val_mse: 8.9367e-04 - lr: 1.0000e-04\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.7292e-04 - mse: 8.7292e-04\n",
      "Epoch 206: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 8.7292e-04 - mse: 8.7292e-04 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 207/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011      \n",
      "Epoch 207: val_mse did not improve from 0.00089\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.0802e-04 - val_mse: 9.0802e-04 - lr: 1.0000e-04\n",
      "Epoch 208/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3556e-04 - mse: 9.3556e-04\n",
      "Epoch 208: val_mse improved from 0.00089 to 0.00088, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 9.2390e-04 - mse: 9.2390e-04 - val_loss: 8.7876e-04 - val_mse: 8.7876e-04 - lr: 1.0000e-04\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.1773e-04 - mse: 9.1773e-04\n",
      "Epoch 209: val_mse improved from 0.00088 to 0.00087, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 9.1773e-04 - mse: 9.1773e-04 - val_loss: 8.7220e-04 - val_mse: 8.7220e-04 - lr: 1.0000e-04\n",
      "Epoch 210/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.5183e-04 - mse: 9.5183e-04\n",
      "Epoch 210: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.4753e-04 - mse: 9.4753e-04 - val_loss: 8.8376e-04 - val_mse: 8.8376e-04 - lr: 1.0000e-04\n",
      "Epoch 211/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 211: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 9.7471e-04 - val_mse: 9.7471e-04 - lr: 1.0000e-04\n",
      "Epoch 212/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.5032e-04 - mse: 8.5032e-04\n",
      "Epoch 212: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 9.2880e-04 - mse: 9.2880e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 213/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7019e-04 - mse: 9.7019e-04\n",
      "Epoch 213: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 9.5172e-04 - mse: 9.5172e-04 - val_loss: 9.2432e-04 - val_mse: 9.2432e-04 - lr: 1.0000e-04\n",
      "Epoch 214/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0012      \n",
      "Epoch 214: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 215/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014 - mse: 0.0014      \n",
      "Epoch 215: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 9.0400e-04 - val_mse: 9.0400e-04 - lr: 1.0000e-04\n",
      "Epoch 216/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010 - mse: 0.0010     \n",
      "Epoch 216: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 8.9270e-04 - val_mse: 8.9270e-04 - lr: 1.0000e-04\n",
      "Epoch 217/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 217: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 8.9005e-04 - val_mse: 8.9005e-04 - lr: 1.0000e-04\n",
      "Epoch 218/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1985e-04 - mse: 7.1985e-04\n",
      "Epoch 218: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 8.3121e-04 - mse: 8.3121e-04 - val_loss: 9.4331e-04 - val_mse: 9.4331e-04 - lr: 1.0000e-04\n",
      "Epoch 219/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.2899e-04 - mse: 9.2899e-04\n",
      "Epoch 219: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 9.6699e-04 - mse: 9.6699e-04 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 220/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.3239e-04 - mse: 8.3239e-04\n",
      "Epoch 220: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 8.4769e-04 - mse: 8.4769e-04 - val_loss: 9.3637e-04 - val_mse: 9.3637e-04 - lr: 1.0000e-04\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 221: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.6308e-04 - val_mse: 9.6308e-04 - lr: 1.0000e-04\n",
      "Epoch 222/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7327e-04 - mse: 8.7327e-04\n",
      "Epoch 222: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 9.1604e-04 - mse: 9.1604e-04 - val_loss: 8.7575e-04 - val_mse: 8.7575e-04 - lr: 1.0000e-04\n",
      "Epoch 223/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2323e-04 - mse: 9.2323e-04\n",
      "Epoch 223: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.8608e-04 - val_mse: 9.8608e-04 - lr: 1.0000e-04\n",
      "Epoch 224/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.8595e-04 - mse: 8.8595e-04\n",
      "Epoch 224: val_mse did not improve from 0.00087\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 9.4785e-04 - mse: 9.4785e-04 - val_loss: 9.1984e-04 - val_mse: 9.1984e-04 - lr: 1.0000e-04\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.7739e-04 - mse: 7.7739e-04\n",
      "Epoch 225: val_mse improved from 0.00087 to 0.00086, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 7.7739e-04 - mse: 7.7739e-04 - val_loss: 8.6125e-04 - val_mse: 8.6125e-04 - lr: 1.0000e-04\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.6826e-04 - mse: 8.6826e-04\n",
      "Epoch 226: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 8.6826e-04 - mse: 8.6826e-04 - val_loss: 8.9861e-04 - val_mse: 8.9861e-04 - lr: 1.0000e-04\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.9570e-04 - mse: 8.9570e-04\n",
      "Epoch 227: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.9570e-04 - mse: 8.9570e-04 - val_loss: 9.3558e-04 - val_mse: 9.3558e-04 - lr: 1.0000e-04\n",
      "Epoch 228/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011     \n",
      "Epoch 228: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.5129e-04 - val_mse: 9.5129e-04 - lr: 1.0000e-04\n",
      "Epoch 229/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.8681e-04 - mse: 9.8681e-04\n",
      "Epoch 229: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 230/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0814e-04 - mse: 7.0814e-04\n",
      "Epoch 230: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 8.2238e-04 - mse: 8.2238e-04 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 231/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.8631e-04 - mse: 7.8631e-04\n",
      "Epoch 231: val_mse did not improve from 0.00086\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 8.9668e-04 - mse: 8.9668e-04 - val_loss: 8.6339e-04 - val_mse: 8.6339e-04 - lr: 1.0000e-04\n",
      "Epoch 232/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.6822e-04 - mse: 8.6822e-04\n",
      "Epoch 232: val_mse improved from 0.00086 to 0.00086, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 8.6461e-04 - mse: 8.6461e-04 - val_loss: 8.5581e-04 - val_mse: 8.5581e-04 - lr: 1.0000e-04\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.0806e-04 - mse: 8.0806e-04\n",
      "Epoch 233: val_mse improved from 0.00086 to 0.00085, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 8.0806e-04 - mse: 8.0806e-04 - val_loss: 8.5439e-04 - val_mse: 8.5439e-04 - lr: 1.0000e-04\n",
      "Epoch 234/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.7368e-04 - mse: 8.7368e-04\n",
      "Epoch 234: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 8.6874e-04 - mse: 8.6874e-04 - val_loss: 8.5875e-04 - val_mse: 8.5875e-04 - lr: 1.0000e-04\n",
      "Epoch 235/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.7469e-04 - mse: 7.7469e-04\n",
      "Epoch 235: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 7.8320e-04 - mse: 7.8320e-04 - val_loss: 8.6920e-04 - val_mse: 8.6920e-04 - lr: 1.0000e-04\n",
      "Epoch 236/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.6520e-04 - mse: 7.6520e-04\n",
      "Epoch 236: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7.6295e-04 - mse: 7.6295e-04 - val_loss: 8.8805e-04 - val_mse: 8.8805e-04 - lr: 1.0000e-04\n",
      "Epoch 237/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.4453e-04 - mse: 9.4453e-04\n",
      "Epoch 237: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 9.3948e-04 - mse: 9.3948e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 238/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 238: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 9.6868e-04 - mse: 9.6868e-04 - val_loss: 8.7175e-04 - val_mse: 8.7175e-04 - lr: 1.0000e-04\n",
      "Epoch 239/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.3617e-04 - mse: 9.3617e-04\n",
      "Epoch 239: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.4849e-04 - mse: 9.4849e-04 - val_loss: 0.0013 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.3779e-04 - mse: 9.3779e-04\n",
      "Epoch 240: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.3779e-04 - mse: 9.3779e-04 - val_loss: 8.9201e-04 - val_mse: 8.9201e-04 - lr: 1.0000e-04\n",
      "Epoch 241/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 7.4544e-04 - mse: 7.4544e-04\n",
      "Epoch 241: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 7.6527e-04 - mse: 7.6527e-04 - val_loss: 8.7462e-04 - val_mse: 8.7462e-04 - lr: 1.0000e-04\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.0170e-04 - mse: 8.0170e-04\n",
      "Epoch 242: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.0170e-04 - mse: 8.0170e-04 - val_loss: 8.6824e-04 - val_mse: 8.6824e-04 - lr: 1.0000e-04\n",
      "Epoch 243/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 243: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 9.9438e-04 - mse: 9.9438e-04 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 244/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.6133e-04 - mse: 9.6133e-04\n",
      "Epoch 244: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 9.4691e-04 - mse: 9.4691e-04 - val_loss: 8.9426e-04 - val_mse: 8.9426e-04 - lr: 1.0000e-04\n",
      "Epoch 245/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.9296e-04 - mse: 9.9296e-04\n",
      "Epoch 245: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 9.8141e-04 - mse: 9.8141e-04 - val_loss: 9.1208e-04 - val_mse: 9.1208e-04 - lr: 1.0000e-04\n",
      "Epoch 246/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.9160e-04 - mse: 9.9160e-04\n",
      "Epoch 246: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 8.8796e-04 - val_mse: 8.8796e-04 - lr: 1.0000e-04\n",
      "Epoch 247/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.8559e-04 - mse: 8.8559e-04\n",
      "Epoch 247: val_mse improved from 0.00085 to 0.00085, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 8.5538e-04 - mse: 8.5538e-04 - val_loss: 8.4724e-04 - val_mse: 8.4724e-04 - lr: 1.0000e-04\n",
      "Epoch 248/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4110e-04 - mse: 8.4110e-04\n",
      "Epoch 248: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.2512e-04 - mse: 8.2512e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 249/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.9927e-04 - mse: 7.9927e-04\n",
      "Epoch 249: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 7.8887e-04 - mse: 7.8887e-04 - val_loss: 8.7038e-04 - val_mse: 8.7038e-04 - lr: 1.0000e-04\n",
      "Epoch 250/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0011     \n",
      "Epoch 250: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.0298e-04 - val_mse: 9.0298e-04 - lr: 1.0000e-04\n",
      "Epoch 251/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7324e-04 - mse: 8.7324e-04\n",
      "Epoch 251: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 9.0523e-04 - mse: 9.0523e-04 - val_loss: 9.1769e-04 - val_mse: 9.1769e-04 - lr: 1.0000e-04\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.6512e-04 - mse: 7.6512e-04\n",
      "Epoch 252: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 7.6512e-04 - mse: 7.6512e-04 - val_loss: 8.5158e-04 - val_mse: 8.5158e-04 - lr: 1.0000e-04\n",
      "Epoch 253/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.1713e-04 - mse: 8.1713e-04\n",
      "Epoch 253: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 8.2950e-04 - mse: 8.2950e-04 - val_loss: 8.9047e-04 - val_mse: 8.9047e-04 - lr: 1.0000e-04\n",
      "Epoch 254/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.6658e-04 - mse: 9.6658e-04\n",
      "Epoch 254: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 9.9477e-04 - mse: 9.9477e-04 - val_loss: 8.7770e-04 - val_mse: 8.7770e-04 - lr: 1.0000e-04\n",
      "Epoch 255/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.7302e-04 - mse: 7.7302e-04\n",
      "Epoch 255: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 8.9113e-04 - mse: 8.9113e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.3467e-04 - mse: 8.3467e-04\n",
      "Epoch 256: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 8.3467e-04 - mse: 8.3467e-04 - val_loss: 9.2681e-04 - val_mse: 9.2681e-04 - lr: 1.0000e-04\n",
      "Epoch 257/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.5117e-04 - mse: 9.5117e-04\n",
      "Epoch 257: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 9.5370e-04 - mse: 9.5370e-04 - val_loss: 9.8881e-04 - val_mse: 9.8881e-04 - lr: 1.0000e-04\n",
      "Epoch 258/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.7219e-04 - mse: 7.7219e-04\n",
      "Epoch 258: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 7.8986e-04 - mse: 7.8986e-04 - val_loss: 9.6603e-04 - val_mse: 9.6603e-04 - lr: 1.0000e-04\n",
      "Epoch 259/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.9047e-04 - mse: 8.9047e-04\n",
      "Epoch 259: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 9.5752e-04 - mse: 9.5752e-04 - val_loss: 8.4894e-04 - val_mse: 8.4894e-04 - lr: 1.0000e-04\n",
      "Epoch 260/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.8551e-04 - mse: 7.8551e-04\n",
      "Epoch 260: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 7.8265e-04 - mse: 7.8265e-04 - val_loss: 8.8898e-04 - val_mse: 8.8898e-04 - lr: 1.0000e-04\n",
      "Epoch 261/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.9552e-04 - mse: 8.9552e-04\n",
      "Epoch 261: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.9981e-04 - mse: 8.9981e-04 - val_loss: 8.8297e-04 - val_mse: 8.8297e-04 - lr: 1.0000e-04\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.1634e-04 - mse: 7.1634e-04\n",
      "Epoch 262: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 7.1634e-04 - mse: 7.1634e-04 - val_loss: 9.0846e-04 - val_mse: 9.0846e-04 - lr: 1.0000e-04\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.8180e-04 - mse: 7.8180e-04\n",
      "Epoch 263: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 7.8180e-04 - mse: 7.8180e-04 - val_loss: 8.5251e-04 - val_mse: 8.5251e-04 - lr: 1.0000e-04\n",
      "Epoch 264/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 7.1509e-04 - mse: 7.1509e-04\n",
      "Epoch 264: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 7.1965e-04 - mse: 7.1965e-04 - val_loss: 9.1714e-04 - val_mse: 9.1714e-04 - lr: 1.0000e-04\n",
      "Epoch 265/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8122e-04 - mse: 9.8122e-04\n",
      "Epoch 265: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 9.9508e-04 - mse: 9.9508e-04 - val_loss: 8.8711e-04 - val_mse: 8.8711e-04 - lr: 1.0000e-04\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0845e-04 - mse: 9.0845e-04\n",
      "Epoch 266: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 9.0845e-04 - mse: 9.0845e-04 - val_loss: 8.7550e-04 - val_mse: 8.7550e-04 - lr: 1.0000e-04\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.3905e-04 - mse: 8.3905e-04\n",
      "Epoch 267: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 8.3905e-04 - mse: 8.3905e-04 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.6833e-04 - mse: 9.6833e-04\n",
      "Epoch 268: val_mse did not improve from 0.00085\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 9.6833e-04 - mse: 9.6833e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 269/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7213e-04 - mse: 8.7213e-04\n",
      "Epoch 269: val_mse improved from 0.00085 to 0.00084, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 8.6445e-04 - mse: 8.6445e-04 - val_loss: 8.4304e-04 - val_mse: 8.4304e-04 - lr: 1.0000e-04\n",
      "Epoch 270/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.2085e-04 - mse: 9.2085e-04\n",
      "Epoch 270: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 9.6346e-04 - mse: 9.6346e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 271/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.9940e-04 - mse: 6.9940e-04\n",
      "Epoch 271: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.0872e-04 - mse: 7.0872e-04 - val_loss: 9.4683e-04 - val_mse: 9.4683e-04 - lr: 1.0000e-04\n",
      "Epoch 272/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0010 - mse: 0.0010       \n",
      "Epoch 272: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 273/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.6828e-04 - mse: 7.6828e-04\n",
      "Epoch 273: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 7.7649e-04 - mse: 7.7649e-04 - val_loss: 8.6736e-04 - val_mse: 8.6736e-04 - lr: 1.0000e-04\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.7245e-04 - mse: 8.7245e-04\n",
      "Epoch 274: val_mse improved from 0.00084 to 0.00084, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 8.7245e-04 - mse: 8.7245e-04 - val_loss: 8.3652e-04 - val_mse: 8.3652e-04 - lr: 1.0000e-04\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.7783e-04 - mse: 7.7783e-04\n",
      "Epoch 275: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 7.7783e-04 - mse: 7.7783e-04 - val_loss: 8.4027e-04 - val_mse: 8.4027e-04 - lr: 1.0000e-04\n",
      "Epoch 276/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.1801e-04 - mse: 8.1801e-04\n",
      "Epoch 276: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 8.1842e-04 - mse: 8.1842e-04 - val_loss: 9.4380e-04 - val_mse: 9.4380e-04 - lr: 1.0000e-04\n",
      "Epoch 277/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.9568e-04 - mse: 7.9568e-04\n",
      "Epoch 277: val_mse did not improve from 0.00084\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 7.7554e-04 - mse: 7.7554e-04 - val_loss: 8.9465e-04 - val_mse: 8.9465e-04 - lr: 1.0000e-04\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0746e-04 - mse: 9.0746e-04\n",
      "Epoch 278: val_mse improved from 0.00084 to 0.00083, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 9.0746e-04 - mse: 9.0746e-04 - val_loss: 8.2912e-04 - val_mse: 8.2912e-04 - lr: 1.0000e-04\n",
      "Epoch 279/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6655e-04 - mse: 8.6655e-04\n",
      "Epoch 279: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 280/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.8481e-04 - mse: 7.8481e-04\n",
      "Epoch 280: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 7.9461e-04 - mse: 7.9461e-04 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.4861e-04 - mse: 9.4861e-04\n",
      "Epoch 281: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.4861e-04 - mse: 9.4861e-04 - val_loss: 9.5215e-04 - val_mse: 9.5215e-04 - lr: 1.0000e-04\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.3125e-04 - mse: 8.3125e-04\n",
      "Epoch 282: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.3125e-04 - mse: 8.3125e-04 - val_loss: 9.2584e-04 - val_mse: 9.2584e-04 - lr: 1.0000e-04\n",
      "Epoch 283/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4360e-04 - mse: 7.4360e-04\n",
      "Epoch 283: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 7.2305e-04 - mse: 7.2305e-04 - val_loss: 9.8299e-04 - val_mse: 9.8299e-04 - lr: 1.0000e-04\n",
      "Epoch 284/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.3983e-04 - mse: 7.3983e-04\n",
      "Epoch 284: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 7.5411e-04 - mse: 7.5411e-04 - val_loss: 8.7347e-04 - val_mse: 8.7347e-04 - lr: 1.0000e-04\n",
      "Epoch 285/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2664e-04 - mse: 8.2664e-04\n",
      "Epoch 285: val_mse did not improve from 0.00083\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 8.3394e-04 - mse: 8.3394e-04 - val_loss: 8.3838e-04 - val_mse: 8.3838e-04 - lr: 1.0000e-04\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0591e-04 - mse: 9.0591e-04\n",
      "Epoch 286: val_mse improved from 0.00083 to 0.00082, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 9.0591e-04 - mse: 9.0591e-04 - val_loss: 8.2424e-04 - val_mse: 8.2424e-04 - lr: 1.0000e-04\n",
      "Epoch 287/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.0218e-04 - mse: 9.0218e-04\n",
      "Epoch 287: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.8088e-04 - mse: 8.8088e-04 - val_loss: 8.7562e-04 - val_mse: 8.7562e-04 - lr: 1.0000e-04\n",
      "Epoch 288/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.2660e-04 - mse: 8.2660e-04\n",
      "Epoch 288: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.2554e-04 - mse: 8.2554e-04 - val_loss: 8.3805e-04 - val_mse: 8.3805e-04 - lr: 1.0000e-04\n",
      "Epoch 289/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.0582e-04 - mse: 9.0582e-04\n",
      "Epoch 289: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.1195e-04 - mse: 9.1195e-04 - val_loss: 8.4678e-04 - val_mse: 8.4678e-04 - lr: 1.0000e-04\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.1694e-04 - mse: 9.1694e-04\n",
      "Epoch 290: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.1694e-04 - mse: 9.1694e-04 - val_loss: 8.8161e-04 - val_mse: 8.8161e-04 - lr: 1.0000e-04\n",
      "Epoch 291/300\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 291: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 8.3442e-04 - val_mse: 8.3442e-04 - lr: 1.0000e-04\n",
      "Epoch 292/300\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.2411e-04 - mse: 9.2411e-04\n",
      "Epoch 292: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 9.3803e-04 - mse: 9.3803e-04 - val_loss: 8.9314e-04 - val_mse: 8.9314e-04 - lr: 1.0000e-04\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.5487e-04 - mse: 7.5487e-04\n",
      "Epoch 293: val_mse did not improve from 0.00082\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 7.5487e-04 - mse: 7.5487e-04 - val_loss: 8.4211e-04 - val_mse: 8.4211e-04 - lr: 1.0000e-04\n",
      "Epoch 294/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 7.0410e-04 - mse: 7.0410e-04\n",
      "Epoch 294: val_mse improved from 0.00082 to 0.00081, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 7.2244e-04 - mse: 7.2244e-04 - val_loss: 8.1293e-04 - val_mse: 8.1293e-04 - lr: 1.0000e-04\n",
      "Epoch 295/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 6.6183e-04 - mse: 6.6183e-04\n",
      "Epoch 295: val_mse did not improve from 0.00081\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.1464e-04 - mse: 8.1464e-04 - val_loss: 0.0010 - val_mse: 0.0010 - lr: 1.0000e-04\n",
      "Epoch 296/300\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 6.7386e-04 - mse: 6.7386e-04\n",
      "Epoch 296: val_mse improved from 0.00081 to 0.00081, saving model to ./Best_model_6.hdf5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 7.2635e-04 - mse: 7.2635e-04 - val_loss: 8.1120e-04 - val_mse: 8.1120e-04 - lr: 1.0000e-04\n",
      "Epoch 297/300\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.9210e-04 - mse: 7.9210e-04\n",
      "Epoch 297: val_mse did not improve from 0.00081\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 7.8474e-04 - mse: 7.8474e-04 - val_loss: 8.3185e-04 - val_mse: 8.3185e-04 - lr: 1.0000e-04\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.8824e-04 - mse: 7.8824e-04\n",
      "Epoch 298: val_mse did not improve from 0.00081\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.8824e-04 - mse: 7.8824e-04 - val_loss: 0.0012 - val_mse: 0.0012 - lr: 1.0000e-04\n",
      "Epoch 299/300\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 8.6315e-04 - mse: 8.6315e-04\n",
      "Epoch 299: val_mse did not improve from 0.00081\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.0521e-04 - mse: 8.0521e-04 - val_loss: 8.2927e-04 - val_mse: 8.2927e-04 - lr: 1.0000e-04\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.4646e-04 - mse: 8.4646e-04\n",
      "Epoch 300: val_mse did not improve from 0.00081\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.4646e-04 - mse: 8.4646e-04 - val_loss: 8.4146e-04 - val_mse: 8.4146e-04 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_1 (Batc  (None, 12)               48        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 24)                12312     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                400       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,679\n",
      "Trainable params: 104,655\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([tf.keras.layers.BatchNormalization(),\n",
    "                           tf.keras.layers.Dense(12,input_dim=12,activation='relu'),\n",
    "                           tf.keras.layers.Dense(64,activation='relu'),\n",
    "                           tf.keras.layers.Dense(128,activation='relu'),\n",
    "                           tf.keras.layers.Dense(128,activation='relu'),\n",
    "                           tf.keras.layers.Dense(512,activation='relu'),\n",
    "                           tf.keras.layers.Dense(24,activation='relu'),\n",
    "                           tf.keras.layers.Dense(16,activation='relu'),\n",
    "                           tf.keras.layers.Dense(3,activation='linear')\n",
    "                           ])\n",
    "model.compile(optimizer='RMSprop',loss='mse',metrics=['mse'])\n",
    "history = model.fit(X_train,Y_train,epochs=300,batch_size=64,validation_split=0.3,callbacks=callbacks_list)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "training_accuracy=history.history['loss'][50:]\n",
    "epochs=range(51,301)\n",
    "vali_ac=history.history['val_loss'][50:]\n",
    "plt.plot(epochs,training_accuracy,'r',label='Training MSE')\n",
    "plt.plot(epochs,vali_ac,'g',label='Validation MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_calculate(yhat,ytrue):\n",
    "    error1 = 0\n",
    "    error2 = 0\n",
    "    error3 = 0\n",
    "    for i in range(len(yhat)):\n",
    "        error1 = error1 + ((ytrue[i,0]-yhat[i,0])**2)\n",
    "        error2 = error2 +  ((ytrue[i,1]-yhat[i,1])**2)\n",
    "        error3 = error3 + ((ytrue[i,2]-yhat[i,2])**2)\n",
    "    print(\"MSE:\",error1/len(yhat),\" \",error2/len(yhat),\" \",error3/len(yhat))\n",
    "    return error1/len(yhat),error2/len(yhat),error3/len(yhat)\n",
    "# Model = tf.keras.models.load_model(filepath)\n",
    "# yhat = Model.predict(X_test)\n",
    "# y1=scaler2.inverse_transform(yhat[:,0].reshape(-1,1))\n",
    "# y2=scaler.inverse_transform(yhat[:,1:].reshape(-1,2))\n",
    "# yhat = np.concatenate([y1,y2],axis=1)\n",
    "# ytrue = Y_test\n",
    "# error_calculate(yhat,ytrue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = ['ROCOF(Predicted)','ROCOF(Actual)','Settling Frequency(Predicted)','Settling Frequency(Actual)','Nadir(Predicted)','Nadir(Actual)']\n",
    "# result_df = pd.DataFrame(columns=column)\n",
    "# result_df['ROCOF(Predicted)']= yhat[:,0]\n",
    "# result_df['Settling Frequency(Predicted)']=yhat[:,1]\n",
    "# result_df['Nadir(Predicted)']=yhat[:,2]\n",
    "# result_df['ROCOF(Actual)']= ytrue[:,0]\n",
    "# result_df['Settling Frequency(Actual)']=ytrue[:,1]\n",
    "# result_df['Nadir(Actual)']=ytrue[:,2]\n",
    "# result_df.to_csv(\"test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=XGBRegressor(alpha=0.1, base_score=None,\n",
       "                                            booster=None, callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.1, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=3,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=XGBRegressor(alpha=0.1, base_score=None,\n",
       "                                            booster=None, callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.1, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=3,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=XGBRegressor(alpha=0.1, base_score=None,\n",
       "                                            booster=None, callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.1, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=3,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, ...))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNNRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5,weights=\"distance\",algorithm=\"auto\",leaf_size=20,p=2)\n",
    "model_KNN = MultiOutputRegressor(knn)\n",
    "model_KNN.fit(X_train,Y_train)\n",
    "\n",
    "#RF Regressor\n",
    "rf = RandomForestRegressor(n_estimators = 10000,max_depth=10,min_samples_split=2,min_samples_leaf=1,max_features='sqrt', random_state = 42)\n",
    "model_RF = MultiOutputRegressor(rf)\n",
    "# model.compile(optimizer='RMSprop',loss='mse',metrics=['mse'])\n",
    "model_RF.fit(X_train,Y_train)\n",
    "#XGB Regressor\n",
    "xgb = XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=3,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                alpha=0.1,\n",
    "                reg_lambda = 0.1,\n",
    "                objective='reg:squarederror')\n",
    "model_XGB = MultiOutputRegressor(xgb)\n",
    "model_XGB.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1396, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving ML models\n",
    "# file name, I'm using *.pickle as a file extension\n",
    "filename_RF = \"random_forest.pickle\"\n",
    "filename_KNN = \"knn.pickle\"\n",
    "filename_XGB = \"xgb.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(model_RF, open(filename_RF, \"wb\"))\n",
    "pickle.dump(model_KNN, open(filename_KNN, \"wb\"))\n",
    "pickle.dump(model_XGB, open(filename_XGB, \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling 3 Models and Inserting To a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath='./val_aux_output_accuracy:{val_accuracy:.3f}-epochs:{epoch:03d}.hdf5'\n",
    "filepath_ens = './Best_model_ensemble.hdf5'\n",
    "#earlyStopping = EarlyStopping(monitor='val_aux_output_loss', patience=10, verbose=0, mode='min')\n",
    "#mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "checkpoint = ModelCheckpoint(filepath_ens, monitor='val_mse', verbose = 1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.5, mode='min',patience=2,verbose=1,min_lr=0.0001)\n",
    "#callbacks_list = [checkpoint]\n",
    "callbacks_list = [checkpoint,reduce_lr]\n",
    "def ensemble_training(model_RF,model_KNN,model_XGB,X_train,Y_train):\n",
    "    y1 = model_RF.predict(X_train)\n",
    "    y2 = model_KNN.predict(X_train)\n",
    "    y3 = model_XGB.predict(X_train)\n",
    "    Y_tr = np.concatenate([y1,y2,y3],axis=1)\n",
    "    print(Y_tr.shape)\n",
    "    model=tf.keras.Sequential([tf.keras.layers.Dense(12,input_dim=9,activation='relu'),\n",
    "                           tf.keras.layers.Dense(64,activation='relu'),\n",
    "                           tf.keras.layers.Dense(128,activation='relu'),\n",
    "                           tf.keras.layers.Dense(128,activation='relu'),\n",
    "                           tf.keras.layers.Dense(512,activation='relu'),\n",
    "                           tf.keras.layers.Dense(512,activation='relu'),\n",
    "                           tf.keras.layers.Dense(265,activation='relu'),\n",
    "                           tf.keras.layers.Dense(24,activation='relu'),\n",
    "                           tf.keras.layers.Dense(16,activation='relu'),\n",
    "                           tf.keras.layers.Dense(3,activation='linear')\n",
    "                           ])\n",
    "    \n",
    "    model.compile(optimizer='RMSprop',loss='mse',metrics=['mse'])\n",
    "    \n",
    "    history = model.fit(Y_tr,Y_train,epochs=300,batch_size=32,validation_split=0.3,callbacks=callbacks_list)\n",
    "    model.summary()\n",
    "    return history, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1396, 9)\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0616 - mse: 0.0616\n",
      "Epoch 1: val_mse improved from inf to 0.01142, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 5s 55ms/step - loss: 0.0616 - mse: 0.0616 - val_loss: 0.0114 - val_mse: 0.0114 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 2: val_mse did not improve from 0.01142\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0191 - val_mse: 0.0191 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 3: val_mse improved from 0.01142 to 0.00436, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0044 - val_mse: 0.0044 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 4: val_mse did not improve from 0.00436\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0055 - val_mse: 0.0055 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 5: val_mse did not improve from 0.00436\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0118 - val_mse: 0.0118 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 6: val_mse improved from 0.00436 to 0.00309, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0031 - val_mse: 0.0031 - lr: 5.0000e-04\n",
      "Epoch 7/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 7: val_mse improved from 0.00309 to 0.00272, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0027 - val_mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 8/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 8: val_mse improved from 0.00272 to 0.00243, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0024 - val_mse: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 9/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 9: val_mse improved from 0.00243 to 0.00110, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 10/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0021 \n",
      "Epoch 10: val_mse improved from 0.00110 to 0.00107, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0011 - val_mse: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 11/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 11: val_mse did not improve from 0.00107\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0027 - val_mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 12/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 8.8960e-04 - mse: 8.8960e-04\n",
      "Epoch 12: val_mse improved from 0.00107 to 0.00064, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 8.4200e-04 - mse: 8.4200e-04 - val_loss: 6.3607e-04 - val_mse: 6.3607e-04 - lr: 2.5000e-04\n",
      "Epoch 13/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.1715e-04 - mse: 9.1715e-04\n",
      "Epoch 13: val_mse improved from 0.00064 to 0.00053, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.9156e-04 - mse: 8.9156e-04 - val_loss: 5.3349e-04 - val_mse: 5.3349e-04 - lr: 2.5000e-04\n",
      "Epoch 14/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.4832e-04 - mse: 8.4832e-04\n",
      "Epoch 14: val_mse did not improve from 0.00053\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 8.1373e-04 - mse: 8.1373e-04 - val_loss: 6.3907e-04 - val_mse: 6.3907e-04 - lr: 2.5000e-04\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.9305e-04 - mse: 8.9305e-04\n",
      "Epoch 15: val_mse did not improve from 0.00053\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 8.9305e-04 - mse: 8.9305e-04 - val_loss: 5.7987e-04 - val_mse: 5.7987e-04 - lr: 2.5000e-04\n",
      "Epoch 16/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 6.6316e-04 - mse: 6.6316e-04\n",
      "Epoch 16: val_mse improved from 0.00053 to 0.00046, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 6.5428e-04 - mse: 6.5428e-04 - val_loss: 4.5903e-04 - val_mse: 4.5903e-04 - lr: 1.2500e-04\n",
      "Epoch 17/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 6.6024e-04 - mse: 6.6024e-04\n",
      "Epoch 17: val_mse improved from 0.00046 to 0.00043, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 6.5520e-04 - mse: 6.5520e-04 - val_loss: 4.3274e-04 - val_mse: 4.3274e-04 - lr: 1.2500e-04\n",
      "Epoch 18/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 6.7107e-04 - mse: 6.7107e-04\n",
      "Epoch 18: val_mse did not improve from 0.00043\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 6.4272e-04 - mse: 6.4272e-04 - val_loss: 4.5683e-04 - val_mse: 4.5683e-04 - lr: 1.2500e-04\n",
      "Epoch 19/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.5462e-04 - mse: 4.5462e-04\n",
      "Epoch 19: val_mse did not improve from 0.00043\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 6.2358e-04 - mse: 6.2358e-04 - val_loss: 5.8021e-04 - val_mse: 5.8021e-04 - lr: 1.2500e-04\n",
      "Epoch 20/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 6.3940e-04 - mse: 6.3940e-04\n",
      "Epoch 20: val_mse improved from 0.00043 to 0.00040, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 6.1134e-04 - mse: 6.1134e-04 - val_loss: 3.9599e-04 - val_mse: 3.9599e-04 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.9805e-04 - mse: 5.9805e-04\n",
      "Epoch 21: val_mse did not improve from 0.00040\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 5.9691e-04 - mse: 5.9691e-04 - val_loss: 4.3798e-04 - val_mse: 4.3798e-04 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.8568e-04 - mse: 5.8568e-04\n",
      "Epoch 22: val_mse did not improve from 0.00040\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 5.8400e-04 - mse: 5.8400e-04 - val_loss: 3.9804e-04 - val_mse: 3.9804e-04 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.8902e-04 - mse: 5.8902e-04\n",
      "Epoch 23: val_mse improved from 0.00040 to 0.00038, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 5.7294e-04 - mse: 5.7294e-04 - val_loss: 3.7954e-04 - val_mse: 3.7954e-04 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.9051e-04 - mse: 5.9051e-04\n",
      "Epoch 24: val_mse did not improve from 0.00038\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 5.7022e-04 - mse: 5.7022e-04 - val_loss: 3.8083e-04 - val_mse: 3.8083e-04 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 5.5487e-04 - mse: 5.5487e-04\n",
      "Epoch 25: val_mse improved from 0.00038 to 0.00036, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 5.5487e-04 - mse: 5.5487e-04 - val_loss: 3.6098e-04 - val_mse: 3.6098e-04 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.7201e-04 - mse: 5.7201e-04\n",
      "Epoch 26: val_mse improved from 0.00036 to 0.00036, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 5.4753e-04 - mse: 5.4753e-04 - val_loss: 3.6065e-04 - val_mse: 3.6065e-04 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.1854e-04 - mse: 4.1854e-04\n",
      "Epoch 27: val_mse did not improve from 0.00036\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 5.4160e-04 - mse: 5.4160e-04 - val_loss: 3.6342e-04 - val_mse: 3.6342e-04 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.3805e-04 - mse: 5.3805e-04\n",
      "Epoch 28: val_mse did not improve from 0.00036\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 5.2965e-04 - mse: 5.2965e-04 - val_loss: 3.6445e-04 - val_mse: 3.6445e-04 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 5.1866e-04 - mse: 5.1866e-04\n",
      "Epoch 29: val_mse improved from 0.00036 to 0.00034, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 5.1866e-04 - mse: 5.1866e-04 - val_loss: 3.4303e-04 - val_mse: 3.4303e-04 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 5.2189e-04 - mse: 5.2189e-04\n",
      "Epoch 30: val_mse did not improve from 0.00034\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 5.2189e-04 - mse: 5.2189e-04 - val_loss: 3.6197e-04 - val_mse: 3.6197e-04 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.1458e-04 - mse: 5.1458e-04\n",
      "Epoch 31: val_mse did not improve from 0.00034\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 5.0674e-04 - mse: 5.0674e-04 - val_loss: 3.6883e-04 - val_mse: 3.6883e-04 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 5.2323e-04 - mse: 5.2323e-04\n",
      "Epoch 32: val_mse did not improve from 0.00034\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 4.9449e-04 - mse: 4.9449e-04 - val_loss: 3.6185e-04 - val_mse: 3.6185e-04 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.5794e-04 - mse: 3.5794e-04\n",
      "Epoch 33: val_mse improved from 0.00034 to 0.00033, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 4.9299e-04 - mse: 4.9299e-04 - val_loss: 3.3150e-04 - val_mse: 3.3150e-04 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.3818e-04 - mse: 3.3818e-04\n",
      "Epoch 34: val_mse did not improve from 0.00033\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 4.7458e-04 - mse: 4.7458e-04 - val_loss: 3.3612e-04 - val_mse: 3.3612e-04 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.9720e-04 - mse: 4.9720e-04\n",
      "Epoch 35: val_mse improved from 0.00033 to 0.00031, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 4.7537e-04 - mse: 4.7537e-04 - val_loss: 3.0546e-04 - val_mse: 3.0546e-04 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.6635e-04 - mse: 4.6635e-04\n",
      "Epoch 36: val_mse did not improve from 0.00031\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 4.5964e-04 - mse: 4.5964e-04 - val_loss: 3.4002e-04 - val_mse: 3.4002e-04 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.5982e-04 - mse: 4.5982e-04\n",
      "Epoch 37: val_mse did not improve from 0.00031\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 4.5301e-04 - mse: 4.5301e-04 - val_loss: 3.3389e-04 - val_mse: 3.3389e-04 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.4799e-04 - mse: 4.4799e-04\n",
      "Epoch 38: val_mse did not improve from 0.00031\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 4.4562e-04 - mse: 4.4562e-04 - val_loss: 3.2429e-04 - val_mse: 3.2429e-04 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.4143e-04 - mse: 4.4143e-04\n",
      "Epoch 39: val_mse improved from 0.00031 to 0.00029, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 4.4143e-04 - mse: 4.4143e-04 - val_loss: 2.9458e-04 - val_mse: 2.9458e-04 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.2995e-04 - mse: 4.2995e-04\n",
      "Epoch 40: val_mse improved from 0.00029 to 0.00029, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 4.2995e-04 - mse: 4.2995e-04 - val_loss: 2.8684e-04 - val_mse: 2.8684e-04 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.3405e-04 - mse: 4.3405e-04\n",
      "Epoch 41: val_mse improved from 0.00029 to 0.00028, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 4.1976e-04 - mse: 4.1976e-04 - val_loss: 2.8201e-04 - val_mse: 2.8201e-04 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.1592e-04 - mse: 4.1592e-04\n",
      "Epoch 42: val_mse improved from 0.00028 to 0.00027, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 4.1052e-04 - mse: 4.1052e-04 - val_loss: 2.7319e-04 - val_mse: 2.7319e-04 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.0293e-04 - mse: 4.0293e-04\n",
      "Epoch 43: val_mse did not improve from 0.00027\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 3.9743e-04 - mse: 3.9743e-04 - val_loss: 2.7362e-04 - val_mse: 2.7362e-04 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 4.2502e-04 - mse: 4.2502e-04\n",
      "Epoch 44: val_mse improved from 0.00027 to 0.00026, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 3.9533e-04 - mse: 3.9533e-04 - val_loss: 2.6053e-04 - val_mse: 2.6053e-04 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.9084e-04 - mse: 3.9084e-04\n",
      "Epoch 45: val_mse improved from 0.00026 to 0.00026, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 3.8558e-04 - mse: 3.8558e-04 - val_loss: 2.5743e-04 - val_mse: 2.5743e-04 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.7756e-04 - mse: 3.7756e-04\n",
      "Epoch 46: val_mse did not improve from 0.00026\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 3.7756e-04 - mse: 3.7756e-04 - val_loss: 2.5835e-04 - val_mse: 2.5835e-04 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.8677e-04 - mse: 3.8677e-04\n",
      "Epoch 47: val_mse improved from 0.00026 to 0.00025, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 3.6953e-04 - mse: 3.6953e-04 - val_loss: 2.4692e-04 - val_mse: 2.4692e-04 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.7422e-04 - mse: 3.7422e-04\n",
      "Epoch 48: val_mse did not improve from 0.00025\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 3.5924e-04 - mse: 3.5924e-04 - val_loss: 2.4784e-04 - val_mse: 2.4784e-04 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.5712e-04 - mse: 3.5712e-04\n",
      "Epoch 49: val_mse improved from 0.00025 to 0.00024, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 3.5712e-04 - mse: 3.5712e-04 - val_loss: 2.4376e-04 - val_mse: 2.4376e-04 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.5563e-04 - mse: 3.5563e-04\n",
      "Epoch 50: val_mse did not improve from 0.00024\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 3.4516e-04 - mse: 3.4516e-04 - val_loss: 2.5263e-04 - val_mse: 2.5263e-04 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.3535e-04 - mse: 3.3535e-04\n",
      "Epoch 51: val_mse did not improve from 0.00024\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 3.3535e-04 - mse: 3.3535e-04 - val_loss: 3.0369e-04 - val_mse: 3.0369e-04 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.4144e-04 - mse: 3.4144e-04\n",
      "Epoch 52: val_mse improved from 0.00024 to 0.00023, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 3.3647e-04 - mse: 3.3647e-04 - val_loss: 2.3057e-04 - val_mse: 2.3057e-04 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.1849e-04 - mse: 3.1849e-04\n",
      "Epoch 53: val_mse improved from 0.00023 to 0.00022, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 3.1849e-04 - mse: 3.1849e-04 - val_loss: 2.2254e-04 - val_mse: 2.2254e-04 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.3276e-04 - mse: 3.3276e-04\n",
      "Epoch 54: val_mse did not improve from 0.00022\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 3.2167e-04 - mse: 3.2167e-04 - val_loss: 2.3086e-04 - val_mse: 2.3086e-04 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.1145e-04 - mse: 3.1145e-04\n",
      "Epoch 55: val_mse improved from 0.00022 to 0.00022, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 3.0672e-04 - mse: 3.0672e-04 - val_loss: 2.2149e-04 - val_mse: 2.2149e-04 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.1155e-04 - mse: 3.1155e-04\n",
      "Epoch 56: val_mse did not improve from 0.00022\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 3.0786e-04 - mse: 3.0786e-04 - val_loss: 2.5650e-04 - val_mse: 2.5650e-04 - lr: 1.0000e-04\n",
      "Epoch 57/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.0380e-04 - mse: 3.0380e-04\n",
      "Epoch 57: val_mse improved from 0.00022 to 0.00022, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 2.9596e-04 - mse: 2.9596e-04 - val_loss: 2.2021e-04 - val_mse: 2.2021e-04 - lr: 1.0000e-04\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.9076e-04 - mse: 2.9076e-04\n",
      "Epoch 58: val_mse improved from 0.00022 to 0.00020, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 2.9076e-04 - mse: 2.9076e-04 - val_loss: 2.0320e-04 - val_mse: 2.0320e-04 - lr: 1.0000e-04\n",
      "Epoch 59/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.8011e-04 - mse: 2.8011e-04\n",
      "Epoch 59: val_mse did not improve from 0.00020\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 2.7788e-04 - mse: 2.7788e-04 - val_loss: 2.0918e-04 - val_mse: 2.0918e-04 - lr: 1.0000e-04\n",
      "Epoch 60/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.8054e-04 - mse: 2.8054e-04\n",
      "Epoch 60: val_mse improved from 0.00020 to 0.00020, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 2.7741e-04 - mse: 2.7741e-04 - val_loss: 1.9600e-04 - val_mse: 1.9600e-04 - lr: 1.0000e-04\n",
      "Epoch 61/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.7794e-04 - mse: 2.7794e-04\n",
      "Epoch 61: val_mse did not improve from 0.00020\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 2.6863e-04 - mse: 2.6863e-04 - val_loss: 2.3035e-04 - val_mse: 2.3035e-04 - lr: 1.0000e-04\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.6959e-04 - mse: 2.6959e-04\n",
      "Epoch 62: val_mse improved from 0.00020 to 0.00020, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 2.6959e-04 - mse: 2.6959e-04 - val_loss: 1.9527e-04 - val_mse: 1.9527e-04 - lr: 1.0000e-04\n",
      "Epoch 63/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.6871e-04 - mse: 2.6871e-04\n",
      "Epoch 63: val_mse did not improve from 0.00020\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 2.6187e-04 - mse: 2.6187e-04 - val_loss: 2.1049e-04 - val_mse: 2.1049e-04 - lr: 1.0000e-04\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.4944e-04 - mse: 2.4944e-04\n",
      "Epoch 64: val_mse did not improve from 0.00020\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.4944e-04 - mse: 2.4944e-04 - val_loss: 2.2280e-04 - val_mse: 2.2280e-04 - lr: 1.0000e-04\n",
      "Epoch 65/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.5070e-04 - mse: 2.5070e-04\n",
      "Epoch 65: val_mse did not improve from 0.00020\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 2.4921e-04 - mse: 2.4921e-04 - val_loss: 2.3405e-04 - val_mse: 2.3405e-04 - lr: 1.0000e-04\n",
      "Epoch 66/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.3534e-04 - mse: 2.3534e-04\n",
      "Epoch 66: val_mse improved from 0.00020 to 0.00019, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 2.4349e-04 - mse: 2.4349e-04 - val_loss: 1.8650e-04 - val_mse: 1.8650e-04 - lr: 1.0000e-04\n",
      "Epoch 67/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.4487e-04 - mse: 2.4487e-04\n",
      "Epoch 67: val_mse did not improve from 0.00019\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 2.4176e-04 - mse: 2.4176e-04 - val_loss: 2.2580e-04 - val_mse: 2.2580e-04 - lr: 1.0000e-04\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.3391e-04 - mse: 2.3391e-04\n",
      "Epoch 68: val_mse improved from 0.00019 to 0.00018, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 2.3391e-04 - mse: 2.3391e-04 - val_loss: 1.7660e-04 - val_mse: 1.7660e-04 - lr: 1.0000e-04\n",
      "Epoch 69/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.3857e-04 - mse: 2.3857e-04\n",
      "Epoch 69: val_mse improved from 0.00018 to 0.00017, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 2.2905e-04 - mse: 2.2905e-04 - val_loss: 1.7337e-04 - val_mse: 1.7337e-04 - lr: 1.0000e-04\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.1422e-04 - mse: 2.1422e-04\n",
      "Epoch 70: val_mse improved from 0.00017 to 0.00017, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 2.1422e-04 - mse: 2.1422e-04 - val_loss: 1.7037e-04 - val_mse: 1.7037e-04 - lr: 1.0000e-04\n",
      "Epoch 71/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.2598e-04 - mse: 2.2598e-04\n",
      "Epoch 71: val_mse improved from 0.00017 to 0.00017, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 2.1692e-04 - mse: 2.1692e-04 - val_loss: 1.6890e-04 - val_mse: 1.6890e-04 - lr: 1.0000e-04\n",
      "Epoch 72/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.0863e-04 - mse: 2.0863e-04\n",
      "Epoch 72: val_mse did not improve from 0.00017\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 2.0971e-04 - mse: 2.0971e-04 - val_loss: 1.8978e-04 - val_mse: 1.8978e-04 - lr: 1.0000e-04\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0480e-04 - mse: 2.0480e-04\n",
      "Epoch 73: val_mse did not improve from 0.00017\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 2.0480e-04 - mse: 2.0480e-04 - val_loss: 1.7037e-04 - val_mse: 1.7037e-04 - lr: 1.0000e-04\n",
      "Epoch 74/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.6021e-04 - mse: 1.6021e-04\n",
      "Epoch 74: val_mse did not improve from 0.00017\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 2.0920e-04 - mse: 2.0920e-04 - val_loss: 1.9817e-04 - val_mse: 1.9817e-04 - lr: 1.0000e-04\n",
      "Epoch 75/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.9821e-04 - mse: 1.9821e-04\n",
      "Epoch 75: val_mse did not improve from 0.00017\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.0340e-04 - mse: 2.0340e-04 - val_loss: 2.6465e-04 - val_mse: 2.6465e-04 - lr: 1.0000e-04\n",
      "Epoch 76/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.9151e-04 - mse: 1.9151e-04\n",
      "Epoch 76: val_mse did not improve from 0.00017\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.8941e-04 - mse: 1.8941e-04 - val_loss: 2.0326e-04 - val_mse: 2.0326e-04 - lr: 1.0000e-04\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.9170e-04 - mse: 1.9170e-04\n",
      "Epoch 77: val_mse improved from 0.00017 to 0.00016, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.9170e-04 - mse: 1.9170e-04 - val_loss: 1.6120e-04 - val_mse: 1.6120e-04 - lr: 1.0000e-04\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.8613e-04 - mse: 1.8613e-04\n",
      "Epoch 78: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.8613e-04 - mse: 1.8613e-04 - val_loss: 2.0895e-04 - val_mse: 2.0895e-04 - lr: 1.0000e-04\n",
      "Epoch 79/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.8476e-04 - mse: 1.8476e-04\n",
      "Epoch 79: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.8371e-04 - mse: 1.8371e-04 - val_loss: 1.7142e-04 - val_mse: 1.7142e-04 - lr: 1.0000e-04\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.7929e-04 - mse: 1.7929e-04\n",
      "Epoch 80: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.7929e-04 - mse: 1.7929e-04 - val_loss: 1.6147e-04 - val_mse: 1.6147e-04 - lr: 1.0000e-04\n",
      "Epoch 81/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.7555e-04 - mse: 1.7555e-04\n",
      "Epoch 81: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.7455e-04 - mse: 1.7455e-04 - val_loss: 1.8830e-04 - val_mse: 1.8830e-04 - lr: 1.0000e-04\n",
      "Epoch 82/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.6729e-04 - mse: 1.6729e-04\n",
      "Epoch 82: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 1.6535e-04 - mse: 1.6535e-04 - val_loss: 1.9335e-04 - val_mse: 1.9335e-04 - lr: 1.0000e-04\n",
      "Epoch 83/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.7582e-04 - mse: 1.7582e-04\n",
      "Epoch 83: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.7578e-04 - mse: 1.7578e-04 - val_loss: 1.8489e-04 - val_mse: 1.8489e-04 - lr: 1.0000e-04\n",
      "Epoch 84/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.7946e-04 - mse: 1.7946e-04\n",
      "Epoch 84: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.7399e-04 - mse: 1.7399e-04 - val_loss: 1.7189e-04 - val_mse: 1.7189e-04 - lr: 1.0000e-04\n",
      "Epoch 85/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.6562e-04 - mse: 1.6562e-04\n",
      "Epoch 85: val_mse improved from 0.00016 to 0.00016, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.6347e-04 - mse: 1.6347e-04 - val_loss: 1.5741e-04 - val_mse: 1.5741e-04 - lr: 1.0000e-04\n",
      "Epoch 86/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.6047e-04 - mse: 1.6047e-04\n",
      "Epoch 86: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.6084e-04 - mse: 1.6084e-04 - val_loss: 1.9168e-04 - val_mse: 1.9168e-04 - lr: 1.0000e-04\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5431e-04 - mse: 1.5431e-04\n",
      "Epoch 87: val_mse did not improve from 0.00016\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.5431e-04 - mse: 1.5431e-04 - val_loss: 1.9641e-04 - val_mse: 1.9641e-04 - lr: 1.0000e-04\n",
      "Epoch 88/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.6519e-04 - mse: 1.6519e-04\n",
      "Epoch 88: val_mse improved from 0.00016 to 0.00015, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 1.6380e-04 - mse: 1.6380e-04 - val_loss: 1.4965e-04 - val_mse: 1.4965e-04 - lr: 1.0000e-04\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5166e-04 - mse: 1.5166e-04\n",
      "Epoch 89: val_mse did not improve from 0.00015\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.5166e-04 - mse: 1.5166e-04 - val_loss: 1.6962e-04 - val_mse: 1.6962e-04 - lr: 1.0000e-04\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5318e-04 - mse: 1.5318e-04\n",
      "Epoch 90: val_mse did not improve from 0.00015\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.5318e-04 - mse: 1.5318e-04 - val_loss: 1.6952e-04 - val_mse: 1.6952e-04 - lr: 1.0000e-04\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5033e-04 - mse: 1.5033e-04\n",
      "Epoch 91: val_mse improved from 0.00015 to 0.00014, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.5033e-04 - mse: 1.5033e-04 - val_loss: 1.3841e-04 - val_mse: 1.3841e-04 - lr: 1.0000e-04\n",
      "Epoch 92/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.2407e-04 - mse: 1.2407e-04\n",
      "Epoch 92: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.4889e-04 - mse: 1.4889e-04 - val_loss: 1.8119e-04 - val_mse: 1.8119e-04 - lr: 1.0000e-04\n",
      "Epoch 93/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.5129e-04 - mse: 1.5129e-04\n",
      "Epoch 93: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.4747e-04 - mse: 1.4747e-04 - val_loss: 1.3881e-04 - val_mse: 1.3881e-04 - lr: 1.0000e-04\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5015e-04 - mse: 1.5015e-04\n",
      "Epoch 94: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.5015e-04 - mse: 1.5015e-04 - val_loss: 1.4179e-04 - val_mse: 1.4179e-04 - lr: 1.0000e-04\n",
      "Epoch 95/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.4797e-04 - mse: 1.4797e-04\n",
      "Epoch 95: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.4751e-04 - mse: 1.4751e-04 - val_loss: 1.6490e-04 - val_mse: 1.6490e-04 - lr: 1.0000e-04\n",
      "Epoch 96/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.4328e-04 - mse: 1.4328e-04\n",
      "Epoch 96: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.4015e-04 - mse: 1.4015e-04 - val_loss: 1.4343e-04 - val_mse: 1.4343e-04 - lr: 1.0000e-04\n",
      "Epoch 97/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.4169e-04 - mse: 1.4169e-04\n",
      "Epoch 97: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.4279e-04 - mse: 1.4279e-04 - val_loss: 1.6073e-04 - val_mse: 1.6073e-04 - lr: 1.0000e-04\n",
      "Epoch 98/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.3804e-04 - mse: 1.3804e-04\n",
      "Epoch 98: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.3673e-04 - mse: 1.3673e-04 - val_loss: 1.5209e-04 - val_mse: 1.5209e-04 - lr: 1.0000e-04\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3616e-04 - mse: 1.3616e-04\n",
      "Epoch 99: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.3616e-04 - mse: 1.3616e-04 - val_loss: 1.7846e-04 - val_mse: 1.7846e-04 - lr: 1.0000e-04\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3040e-04 - mse: 1.3040e-04\n",
      "Epoch 100: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.3040e-04 - mse: 1.3040e-04 - val_loss: 1.9630e-04 - val_mse: 1.9630e-04 - lr: 1.0000e-04\n",
      "Epoch 101/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.3047e-04 - mse: 1.3047e-04\n",
      "Epoch 101: val_mse did not improve from 0.00014\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.2868e-04 - mse: 1.2868e-04 - val_loss: 1.4803e-04 - val_mse: 1.4803e-04 - lr: 1.0000e-04\n",
      "Epoch 102/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.3792e-04 - mse: 1.3792e-04\n",
      "Epoch 102: val_mse improved from 0.00014 to 0.00013, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.3297e-04 - mse: 1.3297e-04 - val_loss: 1.3337e-04 - val_mse: 1.3337e-04 - lr: 1.0000e-04\n",
      "Epoch 103/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.2444e-04 - mse: 1.2444e-04\n",
      "Epoch 103: val_mse improved from 0.00013 to 0.00013, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.2354e-04 - mse: 1.2354e-04 - val_loss: 1.2969e-04 - val_mse: 1.2969e-04 - lr: 1.0000e-04\n",
      "Epoch 104/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.2845e-04 - mse: 1.2845e-04\n",
      "Epoch 104: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.2798e-04 - mse: 1.2798e-04 - val_loss: 1.3615e-04 - val_mse: 1.3615e-04 - lr: 1.0000e-04\n",
      "Epoch 105/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1529e-04 - mse: 1.1529e-04\n",
      "Epoch 105: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.2001e-04 - mse: 1.2001e-04 - val_loss: 1.3356e-04 - val_mse: 1.3356e-04 - lr: 1.0000e-04\n",
      "Epoch 106/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1334e-04 - mse: 1.1334e-04\n",
      "Epoch 106: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.1835e-04 - mse: 1.1835e-04 - val_loss: 1.6978e-04 - val_mse: 1.6978e-04 - lr: 1.0000e-04\n",
      "Epoch 107/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.2572e-04 - mse: 1.2572e-04\n",
      "Epoch 107: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.2349e-04 - mse: 1.2349e-04 - val_loss: 1.4574e-04 - val_mse: 1.4574e-04 - lr: 1.0000e-04\n",
      "Epoch 108/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1438e-04 - mse: 1.1438e-04\n",
      "Epoch 108: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.1707e-04 - mse: 1.1707e-04 - val_loss: 1.4490e-04 - val_mse: 1.4490e-04 - lr: 1.0000e-04\n",
      "Epoch 109/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.1295e-04 - mse: 1.1295e-04\n",
      "Epoch 109: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.1087e-04 - mse: 1.1087e-04 - val_loss: 1.3089e-04 - val_mse: 1.3089e-04 - lr: 1.0000e-04\n",
      "Epoch 110/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1106e-04 - mse: 1.1106e-04\n",
      "Epoch 110: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.2017e-04 - mse: 1.2017e-04 - val_loss: 1.4520e-04 - val_mse: 1.4520e-04 - lr: 1.0000e-04\n",
      "Epoch 111/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1008e-04 - mse: 1.1008e-04\n",
      "Epoch 111: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.1294e-04 - mse: 1.1294e-04 - val_loss: 1.4626e-04 - val_mse: 1.4626e-04 - lr: 1.0000e-04\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1765e-04 - mse: 1.1765e-04\n",
      "Epoch 112: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.1765e-04 - mse: 1.1765e-04 - val_loss: 1.4708e-04 - val_mse: 1.4708e-04 - lr: 1.0000e-04\n",
      "Epoch 113/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.1857e-04 - mse: 1.1857e-04\n",
      "Epoch 113: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 1.1875e-04 - mse: 1.1875e-04 - val_loss: 1.8818e-04 - val_mse: 1.8818e-04 - lr: 1.0000e-04\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0929e-04 - mse: 1.0929e-04\n",
      "Epoch 114: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 1.0929e-04 - mse: 1.0929e-04 - val_loss: 1.8919e-04 - val_mse: 1.8919e-04 - lr: 1.0000e-04\n",
      "Epoch 115/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.1931e-04 - mse: 1.1931e-04\n",
      "Epoch 115: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.1544e-04 - mse: 1.1544e-04 - val_loss: 1.3876e-04 - val_mse: 1.3876e-04 - lr: 1.0000e-04\n",
      "Epoch 116/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.1282e-04 - mse: 1.1282e-04\n",
      "Epoch 116: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.1161e-04 - mse: 1.1161e-04 - val_loss: 1.6345e-04 - val_mse: 1.6345e-04 - lr: 1.0000e-04\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0843e-04 - mse: 1.0843e-04\n",
      "Epoch 117: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 1.0843e-04 - mse: 1.0843e-04 - val_loss: 1.3646e-04 - val_mse: 1.3646e-04 - lr: 1.0000e-04\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1146e-04 - mse: 1.1146e-04\n",
      "Epoch 118: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.1146e-04 - mse: 1.1146e-04 - val_loss: 1.3899e-04 - val_mse: 1.3899e-04 - lr: 1.0000e-04\n",
      "Epoch 119/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0954e-04 - mse: 1.0954e-04\n",
      "Epoch 119: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.1048e-04 - mse: 1.1048e-04 - val_loss: 2.1059e-04 - val_mse: 2.1059e-04 - lr: 1.0000e-04\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0683e-04 - mse: 1.0683e-04\n",
      "Epoch 120: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 1.0683e-04 - mse: 1.0683e-04 - val_loss: 1.3831e-04 - val_mse: 1.3831e-04 - lr: 1.0000e-04\n",
      "Epoch 121/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0813e-04 - mse: 1.0813e-04\n",
      "Epoch 121: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 1.0834e-04 - mse: 1.0834e-04 - val_loss: 1.9947e-04 - val_mse: 1.9947e-04 - lr: 1.0000e-04\n",
      "Epoch 122/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0725e-04 - mse: 1.0725e-04\n",
      "Epoch 122: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 1.0519e-04 - mse: 1.0519e-04 - val_loss: 1.4273e-04 - val_mse: 1.4273e-04 - lr: 1.0000e-04\n",
      "Epoch 123/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0850e-04 - mse: 1.0850e-04\n",
      "Epoch 123: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 1.0769e-04 - mse: 1.0769e-04 - val_loss: 1.2991e-04 - val_mse: 1.2991e-04 - lr: 1.0000e-04\n",
      "Epoch 124/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0132e-04 - mse: 1.0132e-04\n",
      "Epoch 124: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 1.0440e-04 - mse: 1.0440e-04 - val_loss: 2.0151e-04 - val_mse: 2.0151e-04 - lr: 1.0000e-04\n",
      "Epoch 125/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0687e-04 - mse: 1.0687e-04\n",
      "Epoch 125: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.0408e-04 - mse: 1.0408e-04 - val_loss: 1.4109e-04 - val_mse: 1.4109e-04 - lr: 1.0000e-04\n",
      "Epoch 126/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0821e-04 - mse: 1.0821e-04\n",
      "Epoch 126: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0756e-04 - mse: 1.0756e-04 - val_loss: 1.3853e-04 - val_mse: 1.3853e-04 - lr: 1.0000e-04\n",
      "Epoch 127/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.8112e-05 - mse: 9.8112e-05\n",
      "Epoch 127: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.0275e-04 - mse: 1.0275e-04 - val_loss: 2.7716e-04 - val_mse: 2.7716e-04 - lr: 1.0000e-04\n",
      "Epoch 128/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0708e-04 - mse: 1.0708e-04\n",
      "Epoch 128: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.0628e-04 - mse: 1.0628e-04 - val_loss: 1.3987e-04 - val_mse: 1.3987e-04 - lr: 1.0000e-04\n",
      "Epoch 129/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0080e-04 - mse: 1.0080e-04\n",
      "Epoch 129: val_mse did not improve from 0.00013\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.9834e-05 - mse: 9.9834e-05 - val_loss: 1.5069e-04 - val_mse: 1.5069e-04 - lr: 1.0000e-04\n",
      "Epoch 130/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0446e-04 - mse: 1.0446e-04\n",
      "Epoch 130: val_mse improved from 0.00013 to 0.00012, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.0516e-04 - mse: 1.0516e-04 - val_loss: 1.2400e-04 - val_mse: 1.2400e-04 - lr: 1.0000e-04\n",
      "Epoch 131/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0306e-04 - mse: 1.0306e-04\n",
      "Epoch 131: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0470e-04 - mse: 1.0470e-04 - val_loss: 1.7838e-04 - val_mse: 1.7838e-04 - lr: 1.0000e-04\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0680e-04 - mse: 1.0680e-04\n",
      "Epoch 132: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.0680e-04 - mse: 1.0680e-04 - val_loss: 1.5184e-04 - val_mse: 1.5184e-04 - lr: 1.0000e-04\n",
      "Epoch 133/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0356e-04 - mse: 1.0356e-04\n",
      "Epoch 133: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 1.0348e-04 - mse: 1.0348e-04 - val_loss: 1.6802e-04 - val_mse: 1.6802e-04 - lr: 1.0000e-04\n",
      "Epoch 134/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.7765e-05 - mse: 9.7765e-05\n",
      "Epoch 134: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.8496e-05 - mse: 9.8496e-05 - val_loss: 1.8115e-04 - val_mse: 1.8115e-04 - lr: 1.0000e-04\n",
      "Epoch 135/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0330e-04 - mse: 1.0330e-04\n",
      "Epoch 135: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.0236e-04 - mse: 1.0236e-04 - val_loss: 1.5873e-04 - val_mse: 1.5873e-04 - lr: 1.0000e-04\n",
      "Epoch 136/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0885e-04 - mse: 1.0885e-04\n",
      "Epoch 136: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0878e-04 - mse: 1.0878e-04 - val_loss: 1.3618e-04 - val_mse: 1.3618e-04 - lr: 1.0000e-04\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0143e-04 - mse: 1.0143e-04\n",
      "Epoch 137: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.0143e-04 - mse: 1.0143e-04 - val_loss: 1.7602e-04 - val_mse: 1.7602e-04 - lr: 1.0000e-04\n",
      "Epoch 138/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.9392e-05 - mse: 9.9392e-05\n",
      "Epoch 138: val_mse improved from 0.00012 to 0.00012, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.0290e-04 - mse: 1.0290e-04 - val_loss: 1.2039e-04 - val_mse: 1.2039e-04 - lr: 1.0000e-04\n",
      "Epoch 139/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0302e-04 - mse: 1.0302e-04\n",
      "Epoch 139: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0247e-04 - mse: 1.0247e-04 - val_loss: 1.4253e-04 - val_mse: 1.4253e-04 - lr: 1.0000e-04\n",
      "Epoch 140/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.7456e-05 - mse: 9.7456e-05\n",
      "Epoch 140: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.6942e-05 - mse: 9.6942e-05 - val_loss: 1.3734e-04 - val_mse: 1.3734e-04 - lr: 1.0000e-04\n",
      "Epoch 141/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0236e-04 - mse: 1.0236e-04\n",
      "Epoch 141: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0153e-04 - mse: 1.0153e-04 - val_loss: 1.3332e-04 - val_mse: 1.3332e-04 - lr: 1.0000e-04\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0019e-04 - mse: 1.0019e-04\n",
      "Epoch 142: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0019e-04 - mse: 1.0019e-04 - val_loss: 1.3568e-04 - val_mse: 1.3568e-04 - lr: 1.0000e-04\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0052e-04 - mse: 1.0052e-04\n",
      "Epoch 143: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0052e-04 - mse: 1.0052e-04 - val_loss: 1.6979e-04 - val_mse: 1.6979e-04 - lr: 1.0000e-04\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0210e-04 - mse: 1.0210e-04\n",
      "Epoch 144: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.0210e-04 - mse: 1.0210e-04 - val_loss: 1.6104e-04 - val_mse: 1.6104e-04 - lr: 1.0000e-04\n",
      "Epoch 145/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.9918e-05 - mse: 9.9918e-05\n",
      "Epoch 145: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.9724e-05 - mse: 9.9724e-05 - val_loss: 1.5377e-04 - val_mse: 1.5377e-04 - lr: 1.0000e-04\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.5113e-05 - mse: 9.5113e-05\n",
      "Epoch 146: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 9.5113e-05 - mse: 9.5113e-05 - val_loss: 1.5232e-04 - val_mse: 1.5232e-04 - lr: 1.0000e-04\n",
      "Epoch 147/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0447e-04 - mse: 1.0447e-04\n",
      "Epoch 147: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0456e-04 - mse: 1.0456e-04 - val_loss: 1.4906e-04 - val_mse: 1.4906e-04 - lr: 1.0000e-04\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0486e-04 - mse: 1.0486e-04\n",
      "Epoch 148: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0486e-04 - mse: 1.0486e-04 - val_loss: 1.5552e-04 - val_mse: 1.5552e-04 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0600e-04 - mse: 1.0600e-04\n",
      "Epoch 149: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0600e-04 - mse: 1.0600e-04 - val_loss: 1.3667e-04 - val_mse: 1.3667e-04 - lr: 1.0000e-04\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.5495e-05 - mse: 9.5495e-05\n",
      "Epoch 150: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.5495e-05 - mse: 9.5495e-05 - val_loss: 1.2467e-04 - val_mse: 1.2467e-04 - lr: 1.0000e-04\n",
      "Epoch 151/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0053e-04 - mse: 1.0053e-04\n",
      "Epoch 151: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0208e-04 - mse: 1.0208e-04 - val_loss: 1.3388e-04 - val_mse: 1.3388e-04 - lr: 1.0000e-04\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0386e-04 - mse: 1.0386e-04\n",
      "Epoch 152: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.0386e-04 - mse: 1.0386e-04 - val_loss: 1.2281e-04 - val_mse: 1.2281e-04 - lr: 1.0000e-04\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.4673e-05 - mse: 9.4673e-05\n",
      "Epoch 153: val_mse improved from 0.00012 to 0.00012, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 9.4673e-05 - mse: 9.4673e-05 - val_loss: 1.1974e-04 - val_mse: 1.1974e-04 - lr: 1.0000e-04\n",
      "Epoch 154/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0205e-04 - mse: 1.0205e-04\n",
      "Epoch 154: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 1.0388e-04 - mse: 1.0388e-04 - val_loss: 1.4487e-04 - val_mse: 1.4487e-04 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.3722e-05 - mse: 9.3722e-05\n",
      "Epoch 155: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.3313e-05 - mse: 9.3313e-05 - val_loss: 1.2896e-04 - val_mse: 1.2896e-04 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5803e-05 - mse: 9.5803e-05\n",
      "Epoch 156: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.5813e-05 - mse: 9.5813e-05 - val_loss: 1.7044e-04 - val_mse: 1.7044e-04 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5729e-05 - mse: 9.5729e-05\n",
      "Epoch 157: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.8978e-05 - mse: 9.8978e-05 - val_loss: 1.3419e-04 - val_mse: 1.3419e-04 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.4604e-05 - mse: 9.4604e-05\n",
      "Epoch 158: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.6506e-05 - mse: 9.6506e-05 - val_loss: 1.4318e-04 - val_mse: 1.4318e-04 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.2747e-05 - mse: 9.2747e-05\n",
      "Epoch 159: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.2222e-05 - mse: 9.2222e-05 - val_loss: 1.2920e-04 - val_mse: 1.2920e-04 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 9.9893e-05 - mse: 9.9893e-05\n",
      "Epoch 160: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.7406e-05 - mse: 9.7406e-05 - val_loss: 1.3642e-04 - val_mse: 1.3642e-04 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.5856e-05 - mse: 9.5856e-05\n",
      "Epoch 161: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.5856e-05 - mse: 9.5856e-05 - val_loss: 1.4855e-04 - val_mse: 1.4855e-04 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5557e-05 - mse: 9.5557e-05\n",
      "Epoch 162: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.6155e-05 - mse: 9.6155e-05 - val_loss: 1.2926e-04 - val_mse: 1.2926e-04 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0135e-04 - mse: 1.0135e-04\n",
      "Epoch 163: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0083e-04 - mse: 1.0083e-04 - val_loss: 1.2614e-04 - val_mse: 1.2614e-04 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.5459e-05 - mse: 9.5459e-05\n",
      "Epoch 164: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.5177e-05 - mse: 9.5177e-05 - val_loss: 1.3809e-04 - val_mse: 1.3809e-04 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0071e-04 - mse: 1.0071e-04\n",
      "Epoch 165: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.0047e-04 - mse: 1.0047e-04 - val_loss: 1.2287e-04 - val_mse: 1.2287e-04 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.6232e-05 - mse: 9.6232e-05\n",
      "Epoch 166: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.6232e-05 - mse: 9.6232e-05 - val_loss: 1.3485e-04 - val_mse: 1.3485e-04 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5320e-05 - mse: 9.5320e-05\n",
      "Epoch 167: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.4498e-05 - mse: 9.4498e-05 - val_loss: 1.2903e-04 - val_mse: 1.2903e-04 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0388e-04 - mse: 1.0388e-04\n",
      "Epoch 168: val_mse improved from 0.00012 to 0.00012, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.0161e-04 - mse: 1.0161e-04 - val_loss: 1.1947e-04 - val_mse: 1.1947e-04 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.0188e-05 - mse: 9.0188e-05\n",
      "Epoch 169: val_mse did not improve from 0.00012\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.1579e-05 - mse: 9.1579e-05 - val_loss: 1.2998e-04 - val_mse: 1.2998e-04 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.4256e-05 - mse: 9.4256e-05\n",
      "Epoch 170: val_mse improved from 0.00012 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.3225e-05 - mse: 9.3225e-05 - val_loss: 1.1283e-04 - val_mse: 1.1283e-04 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0420e-04 - mse: 1.0420e-04\n",
      "Epoch 171: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.0383e-04 - mse: 1.0383e-04 - val_loss: 1.3257e-04 - val_mse: 1.3257e-04 - lr: 1.0000e-04\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1491e-05 - mse: 9.1491e-05\n",
      "Epoch 172: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.1491e-05 - mse: 9.1491e-05 - val_loss: 1.3987e-04 - val_mse: 1.3987e-04 - lr: 1.0000e-04\n",
      "Epoch 173/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.6342e-05 - mse: 9.6342e-05\n",
      "Epoch 173: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.3555e-05 - mse: 9.3555e-05 - val_loss: 1.2132e-04 - val_mse: 1.2132e-04 - lr: 1.0000e-04\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.9479e-05 - mse: 9.9479e-05\n",
      "Epoch 174: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.9479e-05 - mse: 9.9479e-05 - val_loss: 1.2412e-04 - val_mse: 1.2412e-04 - lr: 1.0000e-04\n",
      "Epoch 175/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.9768e-05 - mse: 9.9768e-05\n",
      "Epoch 175: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.8426e-05 - mse: 9.8426e-05 - val_loss: 1.3574e-04 - val_mse: 1.3574e-04 - lr: 1.0000e-04\n",
      "Epoch 176/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.4425e-05 - mse: 9.4425e-05\n",
      "Epoch 176: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 9.3247e-05 - mse: 9.3247e-05 - val_loss: 1.1882e-04 - val_mse: 1.1882e-04 - lr: 1.0000e-04\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0017e-05 - mse: 9.0017e-05\n",
      "Epoch 177: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 9.0017e-05 - mse: 9.0017e-05 - val_loss: 1.2645e-04 - val_mse: 1.2645e-04 - lr: 1.0000e-04\n",
      "Epoch 178/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0007e-04 - mse: 1.0007e-04\n",
      "Epoch 178: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.0013e-04 - mse: 1.0013e-04 - val_loss: 1.6250e-04 - val_mse: 1.6250e-04 - lr: 1.0000e-04\n",
      "Epoch 179/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.3566e-05 - mse: 9.3566e-05\n",
      "Epoch 179: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.4902e-05 - mse: 9.4902e-05 - val_loss: 1.5079e-04 - val_mse: 1.5079e-04 - lr: 1.0000e-04\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.6618e-05 - mse: 9.6618e-05\n",
      "Epoch 180: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.6618e-05 - mse: 9.6618e-05 - val_loss: 1.1436e-04 - val_mse: 1.1436e-04 - lr: 1.0000e-04\n",
      "Epoch 181/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.6679e-05 - mse: 9.6679e-05\n",
      "Epoch 181: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.7573e-05 - mse: 9.7573e-05 - val_loss: 2.0632e-04 - val_mse: 2.0632e-04 - lr: 1.0000e-04\n",
      "Epoch 182/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.7387e-05 - mse: 9.7387e-05\n",
      "Epoch 182: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.6091e-05 - mse: 9.6091e-05 - val_loss: 1.1247e-04 - val_mse: 1.1247e-04 - lr: 1.0000e-04\n",
      "Epoch 183/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.7822e-05 - mse: 9.7822e-05\n",
      "Epoch 183: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0002e-04 - mse: 1.0002e-04 - val_loss: 1.1388e-04 - val_mse: 1.1388e-04 - lr: 1.0000e-04\n",
      "Epoch 184/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6071e-05 - mse: 8.6071e-05\n",
      "Epoch 184: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.6443e-05 - mse: 8.6443e-05 - val_loss: 1.1799e-04 - val_mse: 1.1799e-04 - lr: 1.0000e-04\n",
      "Epoch 185/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.0074e-05 - mse: 9.0074e-05\n",
      "Epoch 185: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.4024e-05 - mse: 9.4024e-05 - val_loss: 1.7937e-04 - val_mse: 1.7937e-04 - lr: 1.0000e-04\n",
      "Epoch 186/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5155e-05 - mse: 9.5155e-05\n",
      "Epoch 186: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.5362e-05 - mse: 9.5362e-05 - val_loss: 1.7540e-04 - val_mse: 1.7540e-04 - lr: 1.0000e-04\n",
      "Epoch 187/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.5810e-05 - mse: 9.5810e-05\n",
      "Epoch 187: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.6596e-05 - mse: 9.6596e-05 - val_loss: 1.1217e-04 - val_mse: 1.1217e-04 - lr: 1.0000e-04\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.7308e-05 - mse: 9.7308e-05\n",
      "Epoch 188: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.7308e-05 - mse: 9.7308e-05 - val_loss: 1.3657e-04 - val_mse: 1.3657e-04 - lr: 1.0000e-04\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.5810e-05 - mse: 9.5810e-05\n",
      "Epoch 189: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.5810e-05 - mse: 9.5810e-05 - val_loss: 1.2159e-04 - val_mse: 1.2159e-04 - lr: 1.0000e-04\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0294e-04 - mse: 1.0294e-04\n",
      "Epoch 190: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.0294e-04 - mse: 1.0294e-04 - val_loss: 1.1989e-04 - val_mse: 1.1989e-04 - lr: 1.0000e-04\n",
      "Epoch 191/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.3116e-05 - mse: 8.3116e-05\n",
      "Epoch 191: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.8530e-05 - mse: 8.8530e-05 - val_loss: 1.4348e-04 - val_mse: 1.4348e-04 - lr: 1.0000e-04\n",
      "Epoch 192/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.7449e-05 - mse: 9.7449e-05\n",
      "Epoch 192: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.7712e-05 - mse: 9.7712e-05 - val_loss: 1.2962e-04 - val_mse: 1.2962e-04 - lr: 1.0000e-04\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0574e-05 - mse: 9.0574e-05\n",
      "Epoch 193: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0574e-05 - mse: 9.0574e-05 - val_loss: 1.1830e-04 - val_mse: 1.1830e-04 - lr: 1.0000e-04\n",
      "Epoch 194/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.3708e-05 - mse: 9.3708e-05\n",
      "Epoch 194: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.3869e-05 - mse: 9.3869e-05 - val_loss: 1.3939e-04 - val_mse: 1.3939e-04 - lr: 1.0000e-04\n",
      "Epoch 195/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.7821e-05 - mse: 9.7821e-05\n",
      "Epoch 195: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.7328e-05 - mse: 9.7328e-05 - val_loss: 1.2976e-04 - val_mse: 1.2976e-04 - lr: 1.0000e-04\n",
      "Epoch 196/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.2814e-05 - mse: 9.2814e-05\n",
      "Epoch 196: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.3174e-05 - mse: 9.3174e-05 - val_loss: 1.1562e-04 - val_mse: 1.1562e-04 - lr: 1.0000e-04\n",
      "Epoch 197/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6200e-05 - mse: 8.6200e-05\n",
      "Epoch 197: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 8.5607e-05 - mse: 8.5607e-05 - val_loss: 1.0987e-04 - val_mse: 1.0987e-04 - lr: 1.0000e-04\n",
      "Epoch 198/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.5555e-05 - mse: 8.5555e-05\n",
      "Epoch 198: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.8787e-05 - mse: 8.8787e-05 - val_loss: 1.5665e-04 - val_mse: 1.5665e-04 - lr: 1.0000e-04\n",
      "Epoch 199/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.0836e-05 - mse: 9.0836e-05\n",
      "Epoch 199: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9199e-05 - mse: 8.9199e-05 - val_loss: 1.1831e-04 - val_mse: 1.1831e-04 - lr: 1.0000e-04\n",
      "Epoch 200/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.2639e-05 - mse: 9.2639e-05\n",
      "Epoch 200: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.1285e-05 - mse: 9.1285e-05 - val_loss: 1.2891e-04 - val_mse: 1.2891e-04 - lr: 1.0000e-04\n",
      "Epoch 201/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.5276e-05 - mse: 9.5276e-05\n",
      "Epoch 201: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.4459e-05 - mse: 9.4459e-05 - val_loss: 1.0980e-04 - val_mse: 1.0980e-04 - lr: 1.0000e-04\n",
      "Epoch 202/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.3072e-05 - mse: 9.3072e-05\n",
      "Epoch 202: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.0416e-05 - mse: 9.0416e-05 - val_loss: 1.0938e-04 - val_mse: 1.0938e-04 - lr: 1.0000e-04\n",
      "Epoch 203/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8571e-05 - mse: 8.8571e-05\n",
      "Epoch 203: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.7860e-05 - mse: 8.7860e-05 - val_loss: 1.4331e-04 - val_mse: 1.4331e-04 - lr: 1.0000e-04\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.4717e-05 - mse: 9.4717e-05\n",
      "Epoch 204: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 9.4717e-05 - mse: 9.4717e-05 - val_loss: 1.2208e-04 - val_mse: 1.2208e-04 - lr: 1.0000e-04\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.2982e-05 - mse: 9.2982e-05\n",
      "Epoch 205: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.2982e-05 - mse: 9.2982e-05 - val_loss: 1.2250e-04 - val_mse: 1.2250e-04 - lr: 1.0000e-04\n",
      "Epoch 206/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.2211e-05 - mse: 9.2211e-05\n",
      "Epoch 206: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9135e-05 - mse: 8.9135e-05 - val_loss: 1.1653e-04 - val_mse: 1.1653e-04 - lr: 1.0000e-04\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.3134e-05 - mse: 9.3134e-05\n",
      "Epoch 207: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.3134e-05 - mse: 9.3134e-05 - val_loss: 1.1417e-04 - val_mse: 1.1417e-04 - lr: 1.0000e-04\n",
      "Epoch 208/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.6411e-05 - mse: 8.6411e-05\n",
      "Epoch 208: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 8.5106e-05 - mse: 8.5106e-05 - val_loss: 1.4025e-04 - val_mse: 1.4025e-04 - lr: 1.0000e-04\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.4806e-05 - mse: 9.4806e-05\n",
      "Epoch 209: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.4806e-05 - mse: 9.4806e-05 - val_loss: 1.1316e-04 - val_mse: 1.1316e-04 - lr: 1.0000e-04\n",
      "Epoch 210/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.9218e-05 - mse: 8.9218e-05\n",
      "Epoch 210: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.8110e-05 - mse: 8.8110e-05 - val_loss: 1.5231e-04 - val_mse: 1.5231e-04 - lr: 1.0000e-04\n",
      "Epoch 211/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.9647e-05 - mse: 8.9647e-05\n",
      "Epoch 211: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.4046e-05 - mse: 9.4046e-05 - val_loss: 1.6010e-04 - val_mse: 1.6010e-04 - lr: 1.0000e-04\n",
      "Epoch 212/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.2224e-05 - mse: 9.2224e-05\n",
      "Epoch 212: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.4148e-05 - mse: 9.4148e-05 - val_loss: 1.3922e-04 - val_mse: 1.3922e-04 - lr: 1.0000e-04\n",
      "Epoch 213/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 7.9917e-05 - mse: 7.9917e-05\n",
      "Epoch 213: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 8.5211e-05 - mse: 8.5211e-05 - val_loss: 1.8511e-04 - val_mse: 1.8511e-04 - lr: 1.0000e-04\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.2133e-05 - mse: 9.2133e-05\n",
      "Epoch 214: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.2133e-05 - mse: 9.2133e-05 - val_loss: 1.6403e-04 - val_mse: 1.6403e-04 - lr: 1.0000e-04\n",
      "Epoch 215/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8288e-05 - mse: 8.8288e-05\n",
      "Epoch 215: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.9630e-05 - mse: 8.9630e-05 - val_loss: 1.6165e-04 - val_mse: 1.6165e-04 - lr: 1.0000e-04\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0171e-05 - mse: 9.0171e-05\n",
      "Epoch 216: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0171e-05 - mse: 9.0171e-05 - val_loss: 1.4878e-04 - val_mse: 1.4878e-04 - lr: 1.0000e-04\n",
      "Epoch 217/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.3917e-05 - mse: 9.3917e-05\n",
      "Epoch 217: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.2795e-05 - mse: 9.2795e-05 - val_loss: 1.3639e-04 - val_mse: 1.3639e-04 - lr: 1.0000e-04\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0252e-05 - mse: 9.0252e-05\n",
      "Epoch 218: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 9.0252e-05 - mse: 9.0252e-05 - val_loss: 1.0916e-04 - val_mse: 1.0916e-04 - lr: 1.0000e-04\n",
      "Epoch 219/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8922e-05 - mse: 8.8922e-05\n",
      "Epoch 219: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.9129e-05 - mse: 8.9129e-05 - val_loss: 1.8186e-04 - val_mse: 1.8186e-04 - lr: 1.0000e-04\n",
      "Epoch 220/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.1262e-05 - mse: 9.1262e-05\n",
      "Epoch 220: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0001e-05 - mse: 9.0001e-05 - val_loss: 1.3620e-04 - val_mse: 1.3620e-04 - lr: 1.0000e-04\n",
      "Epoch 221/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.5824e-05 - mse: 8.5824e-05\n",
      "Epoch 221: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.5283e-05 - mse: 8.5283e-05 - val_loss: 1.4429e-04 - val_mse: 1.4429e-04 - lr: 1.0000e-04\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.2654e-05 - mse: 9.2654e-05\n",
      "Epoch 222: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.2654e-05 - mse: 9.2654e-05 - val_loss: 1.2726e-04 - val_mse: 1.2726e-04 - lr: 1.0000e-04\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0556e-05 - mse: 9.0556e-05\n",
      "Epoch 223: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0556e-05 - mse: 9.0556e-05 - val_loss: 1.1910e-04 - val_mse: 1.1910e-04 - lr: 1.0000e-04\n",
      "Epoch 224/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.6365e-05 - mse: 9.6365e-05\n",
      "Epoch 224: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.4390e-05 - mse: 9.4390e-05 - val_loss: 1.2351e-04 - val_mse: 1.2351e-04 - lr: 1.0000e-04\n",
      "Epoch 225/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.0892e-05 - mse: 9.0892e-05\n",
      "Epoch 225: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.0466e-05 - mse: 9.0466e-05 - val_loss: 1.4856e-04 - val_mse: 1.4856e-04 - lr: 1.0000e-04\n",
      "Epoch 226/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.2234e-05 - mse: 9.2234e-05\n",
      "Epoch 226: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.2375e-05 - mse: 9.2375e-05 - val_loss: 1.3512e-04 - val_mse: 1.3512e-04 - lr: 1.0000e-04\n",
      "Epoch 227/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.1141e-05 - mse: 9.1141e-05\n",
      "Epoch 227: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.0649e-05 - mse: 9.0649e-05 - val_loss: 1.3261e-04 - val_mse: 1.3261e-04 - lr: 1.0000e-04\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0323e-05 - mse: 9.0323e-05\n",
      "Epoch 228: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.0323e-05 - mse: 9.0323e-05 - val_loss: 1.5441e-04 - val_mse: 1.5441e-04 - lr: 1.0000e-04\n",
      "Epoch 229/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.0946e-05 - mse: 9.0946e-05\n",
      "Epoch 229: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.9125e-05 - mse: 8.9125e-05 - val_loss: 1.2841e-04 - val_mse: 1.2841e-04 - lr: 1.0000e-04\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.2005e-05 - mse: 9.2005e-05\n",
      "Epoch 230: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.2005e-05 - mse: 9.2005e-05 - val_loss: 1.1530e-04 - val_mse: 1.1530e-04 - lr: 1.0000e-04\n",
      "Epoch 231/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.9355e-05 - mse: 8.9355e-05\n",
      "Epoch 231: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.9263e-05 - mse: 8.9263e-05 - val_loss: 1.3503e-04 - val_mse: 1.3503e-04 - lr: 1.0000e-04\n",
      "Epoch 232/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.9254e-05 - mse: 8.9254e-05\n",
      "Epoch 232: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9159e-05 - mse: 8.9159e-05 - val_loss: 1.4834e-04 - val_mse: 1.4834e-04 - lr: 1.0000e-04\n",
      "Epoch 233/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.1782e-05 - mse: 8.1782e-05\n",
      "Epoch 233: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.3949e-05 - mse: 8.3949e-05 - val_loss: 1.5190e-04 - val_mse: 1.5190e-04 - lr: 1.0000e-04\n",
      "Epoch 234/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.0075e-05 - mse: 9.0075e-05\n",
      "Epoch 234: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9523e-05 - mse: 8.9523e-05 - val_loss: 1.2069e-04 - val_mse: 1.2069e-04 - lr: 1.0000e-04\n",
      "Epoch 235/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.3919e-05 - mse: 9.3919e-05\n",
      "Epoch 235: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.6930e-05 - mse: 9.6930e-05 - val_loss: 1.6282e-04 - val_mse: 1.6282e-04 - lr: 1.0000e-04\n",
      "Epoch 236/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.4720e-05 - mse: 8.4720e-05\n",
      "Epoch 236: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.3565e-05 - mse: 8.3565e-05 - val_loss: 1.2393e-04 - val_mse: 1.2393e-04 - lr: 1.0000e-04\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.4833e-05 - mse: 9.4833e-05\n",
      "Epoch 237: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 9.4833e-05 - mse: 9.4833e-05 - val_loss: 1.1917e-04 - val_mse: 1.1917e-04 - lr: 1.0000e-04\n",
      "Epoch 238/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.0330e-05 - mse: 9.0330e-05\n",
      "Epoch 238: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.1521e-05 - mse: 9.1521e-05 - val_loss: 1.4223e-04 - val_mse: 1.4223e-04 - lr: 1.0000e-04\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.8140e-05 - mse: 8.8140e-05\n",
      "Epoch 239: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.8140e-05 - mse: 8.8140e-05 - val_loss: 1.5319e-04 - val_mse: 1.5319e-04 - lr: 1.0000e-04\n",
      "Epoch 240/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.7952e-05 - mse: 8.7952e-05\n",
      "Epoch 240: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.7596e-05 - mse: 8.7596e-05 - val_loss: 1.3139e-04 - val_mse: 1.3139e-04 - lr: 1.0000e-04\n",
      "Epoch 241/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8697e-05 - mse: 8.8697e-05\n",
      "Epoch 241: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.7937e-05 - mse: 8.7937e-05 - val_loss: 1.0709e-04 - val_mse: 1.0709e-04 - lr: 1.0000e-04\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.6427e-05 - mse: 8.6427e-05\n",
      "Epoch 242: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.6427e-05 - mse: 8.6427e-05 - val_loss: 1.5183e-04 - val_mse: 1.5183e-04 - lr: 1.0000e-04\n",
      "Epoch 243/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.0523e-05 - mse: 9.0523e-05\n",
      "Epoch 243: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9490e-05 - mse: 8.9490e-05 - val_loss: 1.4065e-04 - val_mse: 1.4065e-04 - lr: 1.0000e-04\n",
      "Epoch 244/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.1291e-05 - mse: 9.1291e-05\n",
      "Epoch 244: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.3104e-05 - mse: 9.3104e-05 - val_loss: 1.5091e-04 - val_mse: 1.5091e-04 - lr: 1.0000e-04\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1162e-05 - mse: 9.1162e-05\n",
      "Epoch 245: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 9.1162e-05 - mse: 9.1162e-05 - val_loss: 1.2076e-04 - val_mse: 1.2076e-04 - lr: 1.0000e-04\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0199e-05 - mse: 9.0199e-05\n",
      "Epoch 246: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 9.0199e-05 - mse: 9.0199e-05 - val_loss: 1.3984e-04 - val_mse: 1.3984e-04 - lr: 1.0000e-04\n",
      "Epoch 247/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.1836e-05 - mse: 9.1836e-05\n",
      "Epoch 247: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0305e-05 - mse: 9.0305e-05 - val_loss: 1.1011e-04 - val_mse: 1.1011e-04 - lr: 1.0000e-04\n",
      "Epoch 248/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.0919e-05 - mse: 8.0919e-05\n",
      "Epoch 248: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.4433e-05 - mse: 8.4433e-05 - val_loss: 1.1608e-04 - val_mse: 1.1608e-04 - lr: 1.0000e-04\n",
      "Epoch 249/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.7288e-05 - mse: 8.7288e-05\n",
      "Epoch 249: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.5069e-05 - mse: 8.5069e-05 - val_loss: 1.0851e-04 - val_mse: 1.0851e-04 - lr: 1.0000e-04\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0932e-05 - mse: 9.0932e-05\n",
      "Epoch 250: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0932e-05 - mse: 9.0932e-05 - val_loss: 1.1240e-04 - val_mse: 1.1240e-04 - lr: 1.0000e-04\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.9910e-05 - mse: 8.9910e-05\n",
      "Epoch 251: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.9910e-05 - mse: 8.9910e-05 - val_loss: 1.2112e-04 - val_mse: 1.2112e-04 - lr: 1.0000e-04\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.5792e-05 - mse: 8.5792e-05\n",
      "Epoch 252: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.5792e-05 - mse: 8.5792e-05 - val_loss: 1.4070e-04 - val_mse: 1.4070e-04 - lr: 1.0000e-04\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1953e-05 - mse: 9.1953e-05\n",
      "Epoch 253: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 9.1953e-05 - mse: 9.1953e-05 - val_loss: 1.1326e-04 - val_mse: 1.1326e-04 - lr: 1.0000e-04\n",
      "Epoch 254/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.9697e-05 - mse: 8.9697e-05\n",
      "Epoch 254: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.8877e-05 - mse: 8.8877e-05 - val_loss: 1.1784e-04 - val_mse: 1.1784e-04 - lr: 1.0000e-04\n",
      "Epoch 255/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.7688e-05 - mse: 8.7688e-05\n",
      "Epoch 255: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.4983e-05 - mse: 8.4983e-05 - val_loss: 1.0990e-04 - val_mse: 1.0990e-04 - lr: 1.0000e-04\n",
      "Epoch 256/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.4782e-05 - mse: 8.4782e-05\n",
      "Epoch 256: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.5099e-05 - mse: 8.5099e-05 - val_loss: 1.4756e-04 - val_mse: 1.4756e-04 - lr: 1.0000e-04\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.6764e-05 - mse: 8.6764e-05\n",
      "Epoch 257: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 8.6764e-05 - mse: 8.6764e-05 - val_loss: 1.1635e-04 - val_mse: 1.1635e-04 - lr: 1.0000e-04\n",
      "Epoch 258/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.5622e-05 - mse: 8.5622e-05\n",
      "Epoch 258: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.5622e-05 - mse: 8.5622e-05 - val_loss: 1.1783e-04 - val_mse: 1.1783e-04 - lr: 1.0000e-04\n",
      "Epoch 259/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6907e-05 - mse: 8.6907e-05\n",
      "Epoch 259: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.8336e-05 - mse: 8.8336e-05 - val_loss: 1.9395e-04 - val_mse: 1.9395e-04 - lr: 1.0000e-04\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.3856e-05 - mse: 8.3856e-05\n",
      "Epoch 260: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.3856e-05 - mse: 8.3856e-05 - val_loss: 1.1528e-04 - val_mse: 1.1528e-04 - lr: 1.0000e-04\n",
      "Epoch 261/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.5275e-05 - mse: 9.5275e-05\n",
      "Epoch 261: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 9.1798e-05 - mse: 9.1798e-05 - val_loss: 1.0979e-04 - val_mse: 1.0979e-04 - lr: 1.0000e-04\n",
      "Epoch 262/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.1707e-05 - mse: 9.1707e-05\n",
      "Epoch 262: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.1629e-05 - mse: 9.1629e-05 - val_loss: 1.2832e-04 - val_mse: 1.2832e-04 - lr: 1.0000e-04\n",
      "Epoch 263/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.7504e-05 - mse: 8.7504e-05\n",
      "Epoch 263: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.8260e-05 - mse: 8.8260e-05 - val_loss: 1.9438e-04 - val_mse: 1.9438e-04 - lr: 1.0000e-04\n",
      "Epoch 264/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6035e-05 - mse: 8.6035e-05\n",
      "Epoch 264: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.5748e-05 - mse: 8.5748e-05 - val_loss: 1.1976e-04 - val_mse: 1.1976e-04 - lr: 1.0000e-04\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1177e-05 - mse: 9.1177e-05\n",
      "Epoch 265: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.1177e-05 - mse: 9.1177e-05 - val_loss: 1.4648e-04 - val_mse: 1.4648e-04 - lr: 1.0000e-04\n",
      "Epoch 266/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.7405e-05 - mse: 8.7405e-05\n",
      "Epoch 266: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.5876e-05 - mse: 8.5876e-05 - val_loss: 1.1076e-04 - val_mse: 1.1076e-04 - lr: 1.0000e-04\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.9614e-05 - mse: 8.9614e-05\n",
      "Epoch 267: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.9614e-05 - mse: 8.9614e-05 - val_loss: 1.4499e-04 - val_mse: 1.4499e-04 - lr: 1.0000e-04\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.3410e-05 - mse: 8.3410e-05\n",
      "Epoch 268: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 8.3410e-05 - mse: 8.3410e-05 - val_loss: 1.1656e-04 - val_mse: 1.1656e-04 - lr: 1.0000e-04\n",
      "Epoch 269/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.7506e-05 - mse: 8.7506e-05\n",
      "Epoch 269: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.6427e-05 - mse: 8.6427e-05 - val_loss: 1.1239e-04 - val_mse: 1.1239e-04 - lr: 1.0000e-04\n",
      "Epoch 270/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.5535e-05 - mse: 9.5535e-05\n",
      "Epoch 270: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.7007e-05 - mse: 9.7007e-05 - val_loss: 1.3863e-04 - val_mse: 1.3863e-04 - lr: 1.0000e-04\n",
      "Epoch 271/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6508e-05 - mse: 8.6508e-05\n",
      "Epoch 271: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.6258e-05 - mse: 8.6258e-05 - val_loss: 1.4109e-04 - val_mse: 1.4109e-04 - lr: 1.0000e-04\n",
      "Epoch 272/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.5070e-05 - mse: 8.5070e-05\n",
      "Epoch 272: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.4718e-05 - mse: 8.4718e-05 - val_loss: 1.4444e-04 - val_mse: 1.4444e-04 - lr: 1.0000e-04\n",
      "Epoch 273/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.7098e-05 - mse: 8.7098e-05\n",
      "Epoch 273: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.6849e-05 - mse: 8.6849e-05 - val_loss: 1.4639e-04 - val_mse: 1.4639e-04 - lr: 1.0000e-04\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.5604e-05 - mse: 8.5604e-05\n",
      "Epoch 274: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.5604e-05 - mse: 8.5604e-05 - val_loss: 1.1613e-04 - val_mse: 1.1613e-04 - lr: 1.0000e-04\n",
      "Epoch 275/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.3261e-05 - mse: 8.3261e-05\n",
      "Epoch 275: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.5002e-05 - mse: 8.5002e-05 - val_loss: 1.1903e-04 - val_mse: 1.1903e-04 - lr: 1.0000e-04\n",
      "Epoch 276/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.3769e-05 - mse: 8.3769e-05\n",
      "Epoch 276: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.3599e-05 - mse: 8.3599e-05 - val_loss: 1.2229e-04 - val_mse: 1.2229e-04 - lr: 1.0000e-04\n",
      "Epoch 277/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.6891e-05 - mse: 9.6891e-05\n",
      "Epoch 277: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.6093e-05 - mse: 9.6093e-05 - val_loss: 1.1875e-04 - val_mse: 1.1875e-04 - lr: 1.0000e-04\n",
      "Epoch 278/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.5024e-05 - mse: 8.5024e-05\n",
      "Epoch 278: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.5680e-05 - mse: 8.5680e-05 - val_loss: 1.1733e-04 - val_mse: 1.1733e-04 - lr: 1.0000e-04\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.8653e-05 - mse: 8.8653e-05\n",
      "Epoch 279: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.8653e-05 - mse: 8.8653e-05 - val_loss: 1.2080e-04 - val_mse: 1.2080e-04 - lr: 1.0000e-04\n",
      "Epoch 280/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.2931e-05 - mse: 8.2931e-05\n",
      "Epoch 280: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.2216e-05 - mse: 8.2216e-05 - val_loss: 1.5041e-04 - val_mse: 1.5041e-04 - lr: 1.0000e-04\n",
      "Epoch 281/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.6084e-05 - mse: 9.6084e-05\n",
      "Epoch 281: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 9.5097e-05 - mse: 9.5097e-05 - val_loss: 1.0608e-04 - val_mse: 1.0608e-04 - lr: 1.0000e-04\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.1275e-05 - mse: 8.1275e-05\n",
      "Epoch 282: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.1275e-05 - mse: 8.1275e-05 - val_loss: 1.4812e-04 - val_mse: 1.4812e-04 - lr: 1.0000e-04\n",
      "Epoch 283/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.4167e-05 - mse: 8.4167e-05\n",
      "Epoch 283: val_mse improved from 0.00011 to 0.00011, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 8.3710e-05 - mse: 8.3710e-05 - val_loss: 1.0558e-04 - val_mse: 1.0558e-04 - lr: 1.0000e-04\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.4806e-05 - mse: 8.4806e-05\n",
      "Epoch 284: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.4806e-05 - mse: 8.4806e-05 - val_loss: 1.3961e-04 - val_mse: 1.3961e-04 - lr: 1.0000e-04\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1036e-05 - mse: 9.1036e-05\n",
      "Epoch 285: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.1036e-05 - mse: 9.1036e-05 - val_loss: 1.3586e-04 - val_mse: 1.3586e-04 - lr: 1.0000e-04\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.8269e-05 - mse: 8.8269e-05\n",
      "Epoch 286: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.8269e-05 - mse: 8.8269e-05 - val_loss: 1.3677e-04 - val_mse: 1.3677e-04 - lr: 1.0000e-04\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.7027e-05 - mse: 8.7027e-05\n",
      "Epoch 287: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 8.7027e-05 - mse: 8.7027e-05 - val_loss: 1.4592e-04 - val_mse: 1.4592e-04 - lr: 1.0000e-04\n",
      "Epoch 288/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8367e-05 - mse: 8.8367e-05\n",
      "Epoch 288: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.9186e-05 - mse: 8.9186e-05 - val_loss: 1.4935e-04 - val_mse: 1.4935e-04 - lr: 1.0000e-04\n",
      "Epoch 289/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.6990e-05 - mse: 8.6990e-05\n",
      "Epoch 289: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 8.5823e-05 - mse: 8.5823e-05 - val_loss: 1.2564e-04 - val_mse: 1.2564e-04 - lr: 1.0000e-04\n",
      "Epoch 290/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.1316e-05 - mse: 9.1316e-05\n",
      "Epoch 290: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 9.0986e-05 - mse: 9.0986e-05 - val_loss: 1.3296e-04 - val_mse: 1.3296e-04 - lr: 1.0000e-04\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.6854e-05 - mse: 8.6854e-05\n",
      "Epoch 291: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.6854e-05 - mse: 8.6854e-05 - val_loss: 1.3546e-04 - val_mse: 1.3546e-04 - lr: 1.0000e-04\n",
      "Epoch 292/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.7040e-05 - mse: 8.7040e-05\n",
      "Epoch 292: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.6426e-05 - mse: 8.6426e-05 - val_loss: 1.2175e-04 - val_mse: 1.2175e-04 - lr: 1.0000e-04\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.4639e-05 - mse: 8.4639e-05\n",
      "Epoch 293: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.4639e-05 - mse: 8.4639e-05 - val_loss: 1.1986e-04 - val_mse: 1.1986e-04 - lr: 1.0000e-04\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.1272e-05 - mse: 8.1272e-05\n",
      "Epoch 294: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.1272e-05 - mse: 8.1272e-05 - val_loss: 1.0957e-04 - val_mse: 1.0957e-04 - lr: 1.0000e-04\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.0956e-05 - mse: 8.0956e-05\n",
      "Epoch 295: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 8.0956e-05 - mse: 8.0956e-05 - val_loss: 1.4649e-04 - val_mse: 1.4649e-04 - lr: 1.0000e-04\n",
      "Epoch 296/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 9.2812e-05 - mse: 9.2812e-05\n",
      "Epoch 296: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 9.1261e-05 - mse: 9.1261e-05 - val_loss: 1.1101e-04 - val_mse: 1.1101e-04 - lr: 1.0000e-04\n",
      "Epoch 297/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.6120e-05 - mse: 8.6120e-05\n",
      "Epoch 297: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 8.6405e-05 - mse: 8.6405e-05 - val_loss: 1.5669e-04 - val_mse: 1.5669e-04 - lr: 1.0000e-04\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.8957e-05 - mse: 8.8957e-05\n",
      "Epoch 298: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.8957e-05 - mse: 8.8957e-05 - val_loss: 1.1064e-04 - val_mse: 1.1064e-04 - lr: 1.0000e-04\n",
      "Epoch 299/300\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 8.8683e-05 - mse: 8.8683e-05\n",
      "Epoch 299: val_mse did not improve from 0.00011\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 8.7482e-05 - mse: 8.7482e-05 - val_loss: 1.1233e-04 - val_mse: 1.1233e-04 - lr: 1.0000e-04\n",
      "Epoch 300/300\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.5420e-05 - mse: 8.5420e-05\n",
      "Epoch 300: val_mse improved from 0.00011 to 0.00010, saving model to ./Best_model_ensemble.hdf5\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 8.4563e-05 - mse: 8.4563e-05 - val_loss: 1.0213e-04 - val_mse: 1.0213e-04 - lr: 1.0000e-04\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 12)                120       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 265)               135945    \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 24)                6384      \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 16)                400       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497,268\n",
      "Trainable params: 497,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history, mod = ensemble_training(model_RF,model_KNN,model_XGB,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model,X_test,Y_test,model_KNN,model_XGB,model_RF):\n",
    "    y1 = model_RF.predict(X_test)\n",
    "    y2 = model_KNN.predict(X_test)\n",
    "    y3 = model_XGB.predict(X_test)\n",
    "    X = np.concatenate([y1,y2,y3],axis=1)\n",
    "    yhat = model.predict(X)\n",
    "    Y1=scaler2.inverse_transform(yhat[:,0].reshape(-1,1))\n",
    "    Y2=scaler.inverse_transform(yhat[:,1:].reshape(-1,2))\n",
    "    yhat = np.concatenate([Y1,Y2],axis=1)\n",
    "    ytrue = Y_test\n",
    "    x, y, z = error_calculate(yhat,ytrue)\n",
    "    return x, y, z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between 4 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_columns = ['Model Name','ROCOF','Settling Frequency','Nadir']\n",
    "comparison_df = pd.DataFrame(columns = comp_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error(model,X_test,Y_test):\n",
    "    yhat = model.predict(X_test)\n",
    "    y1=scaler2.inverse_transform(yhat[:,0].reshape(-1,1))\n",
    "    y2=scaler.inverse_transform(yhat[:,1:].reshape(-1,2))\n",
    "    yhat = np.concatenate([y1,y2],axis=1)\n",
    "    ytrue = Y_test\n",
    "    x, y, z = error_calculate(yhat,ytrue)\n",
    "    return x, y, z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step\n",
      "MSE: 0.00016884004574597536   0.030201617967601253   0.018410582632527973\n",
      "MSE: 2.2623759936529936e-05   0.00852064085094129   0.0008465672845918053\n",
      "MSE: 4.50857046167494e-05   0.008590601813766438   0.005287016206090671\n",
      "MSE: 2.767323223115843e-05   0.009390174292764212   0.0024225778704086006\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "MSE: 6.311049515536969e-05   0.004704647571856369   0.0017641985928518822\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(filepath)\n",
    "rocof_ANN,setl_ANN,nadir_ANN = find_error(model,X_test,Y_test)\n",
    "model = model_KNN\n",
    "rocof_KNN,setl_KNN,nadir_KNN = find_error(model,X_test,Y_test)\n",
    "model = model_RF\n",
    "rocof_RF,setl_RF,nadir_RF = find_error(model,X_test,Y_test)\n",
    "model = model_XGB\n",
    "rocof_XGB,setl_XGB,nadir_XGB = find_error(model,X_test,Y_test)\n",
    "model_ensemble = tf.keras.models.load_model(filepath_ens)\n",
    "rocof_ensemble, setl_ensemble,nadir_ensemble = model_inference(model_ensemble,X_test,Y_test,model_KNN,model_XGB,model_RF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df['Model Name'] = ['DNN','KNN','RF','XGB','Merged Model']\n",
    "comparison_df['ROCOF']= [rocof_ANN,rocof_KNN,rocof_RF,rocof_XGB,rocof_ensemble]\n",
    "comparison_df['Settling Frequency']= [setl_ANN,setl_KNN,setl_RF,setl_XGB,setl_ensemble]\n",
    "comparison_df['Nadir']=[nadir_ANN,nadir_KNN,nadir_RF,nadir_XGB,nadir_ensemble]\n",
    "\n",
    "comparison_df.to_csv(\"comparison_result_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
